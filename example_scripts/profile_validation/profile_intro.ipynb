{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fce85142",
   "metadata": {},
   "source": [
    "\n",
    "##  Example useage of Profile object.\n",
    "\n",
    "### Overview\n",
    "\n",
    "INDEXED type class for storing data from a CTD Profile (or similar\n",
    "down and up observations). The structure of the class is based around having\n",
    "discrete profile locations with independent depth dimensions and coords. \n",
    "The class dataset should contain two dimensions:\n",
    "\n",
    "    > id_dim      :: The profiles dimension. Each element of this dimension\n",
    "                 contains data (e.g. cast) for an individual location.\n",
    "    > z_dim   :: The dimension for depth levels. A profile object does not\n",
    "                 need to have shared depths, so NaNs might be used to\n",
    "                 pad any depth array.\n",
    "\n",
    "Alongside these dimensions, the following minimal coordinates should also\n",
    "be available:\n",
    "\n",
    "    > longitude (id_dim)   :: 1D array of longitudes, one for each id_dim\n",
    "    > latitude  (id_dim)   :: 1D array of latitudes, one for each id_dim\n",
    "    > time      (id_dim)   :: 1D array of times, one for each id_dim\n",
    "    > depth     (id_dim, z_dim)  :: 2D array of depths, with different depth\n",
    "                                levels being provided for each profile.\n",
    "                                Note that these depth levels need to be\n",
    "                                stored in a 2D array, so NaNs can be used\n",
    "                                to pad out profiles with shallower depths.\n",
    "    > id_name   (id_dim)   :: [Optional] Name of id_dim/case or id_dim number.\n",
    "\n",
    "## Example Useage\n",
    "\n",
    "Below is a description of the available example scripts for this class as well\n",
    "as an overview of validation using` Profile` and `ProfileAnalysis`.\n",
    "\n",
    "### Example Scripts\n",
    "\n",
    "Please see COAsT/example_scripts/profile_validation for some scripts which\n",
    "demonstrate how to use the Profile and ProfileAnalysis classes for model\n",
    "validation. \n",
    "\n",
    "1. `analysis_preprocess_en4.py` : If you're using EN4 data, this kind of script\n",
    "might be your first step for analysis.\n",
    "\n",
    "2. `analysis_extract_and_compare.py`: This script shows you how to extract\n",
    "the nearest model profiles, compare them with EN4 observations and get errors\n",
    "throughout the vertical dimension and averaged in surface and bottom zones\n",
    "\n",
    "3. `analysis_extract_and_compare_single_process.py`: This script does the same\n",
    "as number 2. However, it is modified slightly to take a command line argument\n",
    "which helps it figure out which dates to analyse. This means that this script\n",
    "can act as a template for `jug` type parallel processing on, e.g. JASMIN.\n",
    "\n",
    "4. `analysis_mask_means.py`: This script demonstrates how to use boolean masks\n",
    "to obtain regional averages of profiles and errors.\n",
    "\n",
    "5. `analysis_average_into_grid_boxes.py`: This script demonstrates how to \n",
    "average the data inside a `Profile` object into regular grid boxes and \n",
    "seasonal climatologies.\n",
    "\n",
    "### Basic useage\n",
    "\n",
    "We can create a new Profile object easily:\n",
    "\n",
    "```\n",
    "profile = coast.Profile()\n",
    "```\n",
    "\n",
    "Currently, this object is empty, and contains no dataset. There are some\n",
    "reading routines currently available in Profile for reading EN4 or WOD data\n",
    "files. These can be used to easily read data into your new profile object:\n",
    "\n",
    "```\n",
    "# Read WOD data into profile object (OVERWRITES DATASET)\n",
    "profile.read_wod( filename )\n",
    "\n",
    "# Read EN4 data into profile object\n",
    "profile.read_en4( filename )\n",
    "```\n",
    "\n",
    "Alternatively, you can pass an `xarray.dataset` straight to Profile:\n",
    "```\n",
    "profile = coast.Profile( dataset = your_dataset, config = config_file [opt] )\n",
    "```\n",
    "\n",
    "We can do some simple spatial and temporal manipulations of this data:\n",
    "\n",
    "```\n",
    "# Cut out a geographical box\n",
    "profile = profile.subset_indices_lonlat_box(lonbounds = [-15, 15], \n",
    "                                            latbounds = [45, 65])\n",
    "\n",
    "# Cut out a time window\n",
    "profile = profile.time_slice( date0 = datetime(2004, 1, 1), date1 = datetime(2005,1,1))\n",
    "```\n",
    "\n",
    "If you are using EN4 data, you can use the `process_en4()` routine to apply \n",
    "quality control flags to the data (replacing with NaNs):\n",
    "\n",
    "```\n",
    "processed_profile = profile.process_en4()\n",
    "```\n",
    "\n",
    "### Direct Model Comparison\n",
    "\n",
    "There are a number of routines available for interpolating in the horizontal,\n",
    "vertical and in time to do direct comparisons of model and profile data.\n",
    "`Profile.obs_operator` will do a nearest neighbour spatial interpolation of\n",
    "the data in a `Gridded` object to profile latitudes/longitudes. It will also\n",
    "do a custom time interpolation. For example:\n",
    "\n",
    "```\n",
    "# Create gridded object:\n",
    "nemo = coast.Gridded(fn_dat, fn_dom, multiple=True, config=fn_cfg_nemo)\n",
    "\n",
    "# Create a landmask array in Gridded\n",
    "nemo.dataset[\"landmask\"] = nemo.dataset.bottom_level == 0\n",
    "nemo.dataset = nemo.dataset.rename({\"depth_0\": \"depth\"})\n",
    "\n",
    "# Use obs operator for horizontal remapping of Gridded onto Profile.\n",
    "model_profiles = profile.obs_operator(nemo)\n",
    "```\n",
    "\n",
    "In the above example we added a `landmask` variable to the `Gridded` dataset.\n",
    "When this is present, the `obs_operator` will use this to interpolation to the\n",
    "nearest *wet* point. If not present, it will just take the nearest grid point.\n",
    "\n",
    "Now that we have interpolated the model onto Profiles, we have a new Profile\n",
    "object called `model_profiles`. This can be used to do some comparisons with\n",
    "our original `processed_profile` object, which we created above. First lets\n",
    "make our ProfileAnalysis object:\n",
    "\n",
    "```\n",
    "analysis = coast.ProfileAnalysis()\n",
    "```\n",
    "\n",
    "We can use `ProfileAnalysis.interpolate_vertical` to interpolate all variables\n",
    "within a Profile object. This can be done onto a set of reference depths or,\n",
    "matching another object's depth coordinates by passing another profile object.\n",
    "Let's interpolate our model profiles onto observations depths, then interpolate\n",
    "both onto a set of reference depths:\n",
    "\n",
    "```\n",
    "# Interpolate model profiles onto observation depths\n",
    "model_profiles_interp = analysis.interpolate_vertical(model_profiles, profile, interp_method=\"linear\")\n",
    "\n",
    "# Vertical interpolation of model profiles to reference depths\n",
    "model_profiles_interp = panalysis.interpolate_vertical(model_profiles_interp, ref_depth)\n",
    "\n",
    "# Interpolation of obs profiles to reference depths\n",
    "profile_interp = analysis.interpolate_vertical(profile, ref_depth)\n",
    "```\n",
    "\n",
    "Now that we have two Profile objects that are horizontally and vertically \n",
    "comparable, we can use `difference()` to get some basic errors:\n",
    "\n",
    "```\n",
    "differences = analysis.difference(profile_interp, model_profiles_interp)\n",
    "``` \n",
    "\n",
    "This will return a new `Profile` object that contains the variable difference,\n",
    "absolute differences and square differences at all depths and means for each\n",
    "profile.\n",
    "\n",
    "### Layer Averaging\n",
    "\n",
    "We can use the `Profile` object to get mean values between specific depth levels\n",
    "or for some layer above the bathymetric depth. The former can be done using\n",
    "`ProfileAnalysis.depth_means()`, for example the following will return a new\n",
    "Profile object containing the means of all variables between 0m and 5m:\n",
    "\n",
    "```\n",
    "profile_surface = analysis.depth_means(profile, [0, 5])\n",
    "```\n",
    "\n",
    "This can be done for any arbitrary depth layer defined by two depths. In some\n",
    "cases it may be that one of the depth levels is not defined by a constant, e.g.\n",
    "when calculating bottom means. In this case you may want to calculate averages\n",
    "in some layer above the seabed. This can be done using \n",
    "`ProfileAnalysis.bottom_means()`. For example:\n",
    "\n",
    "```\n",
    "bottom_height = [10, 30, 100]  # Use bottom heights of 10m, 30m and 100m for...\n",
    "bottom_thresh = [100, 500, np.inf]  # ...depths less than 100m, 500m and infinite\n",
    "profile_bottom = analysis.bottom_means(profile, bottom_height, bottom_thresh)\n",
    "```\n",
    "\n",
    "This will calculate bottom means differently depending upon the actualy depth.\n",
    "For depths less than 100m, it will take the average of the bottom 10m. For less\n",
    "than 500 m (and greater than 100m), it will take the average of the bottom 30m.\n",
    "And so on. This routine will look for a variable in the input Profile called\n",
    "`bathymetry`. If this is not present you will need to insert it yourself, e.g:\n",
    "\n",
    "```\n",
    "profile.dataset[\"bathymetry\"] = ([\"id_dim\"], obs_bathymetry_array)\n",
    "```\n",
    "\n",
    "**NOTE1: The `bathymetry` variable does not actually need to contain bathymetric\n",
    "depths, it can also be used to calculate means above any non-constant surface.\n",
    "For example, it could be mixed layer depth.\n",
    "\n",
    "**NOTE2: This can be done for any Profile object. So, you could use this \n",
    "workflow to also average a Profile derived from the `difference()` routine.\n",
    "\n",
    "### Regional (Mask) Averaging\n",
    "\n",
    "We can use `Profile` in combination with `MaskMaker` to calculate averages over\n",
    "regions defined by masks. For example, to get the mean errors in the North Sea.\n",
    "Start by creating a list of boolean masks we would like to use:\n",
    "\n",
    "```\n",
    "mm = coast.MaskMaker()\n",
    "\n",
    "# Define Regional Masks\n",
    "regional_masks = []\n",
    "bath = nemo.dataset.bathymetry.values\n",
    "\n",
    "# Add regional mask for whole domain\n",
    "regional_masks.append(np.ones(lon.shape))\n",
    "\n",
    "# Add regional mask for North Sea\n",
    "regional_masks.append(mm.region_def_nws_north_sea(lon, lat, bath))\n",
    "\n",
    "region_names = [\"whole_domain\",\"north_sea\",]\n",
    "```\n",
    "\n",
    "Next, we must make these masks into datasets using `MaskMaker.make_mask_dataset`.\n",
    "Masks should be 2D datasets defined by booleans. In our example here we have used\n",
    "the latitude/longitude array from the nemo object, however it can be defined\n",
    "however you like.\n",
    "\n",
    "```\n",
    "mask_list = mm.make_mask_dataset(lon, lat, regional_masks)\n",
    "```\n",
    "\n",
    "Then we use `ProfileAnalysis.determine_mask_indices` to figure out which\n",
    "profiles in a `Profile` object lie within each regional mask:\n",
    "\n",
    "```\n",
    "mask_indices = analysis.determine_mask_indices(profile, mask_list)\n",
    "```\n",
    "\n",
    "This returns an object called `mask_indices`, which is required to pass to\n",
    "`ProfileAnalysis.mask_means()`. This routine will return a new xarray dataset\n",
    "containing averaged data for each region:\n",
    "\n",
    "```\n",
    "mask_means = analysis.mask_means(profile, mask_indices)\n",
    "```\n",
    "\n",
    "### Gridding Profile Data\n",
    "\n",
    "If you have large amount of profile data you may want to average it into\n",
    "grid boxes to get, for example, mean error maps or climatologies. This can be\n",
    "done using `ProfileAnalysis.average_into_grid_boxes()`.\n",
    "\n",
    "We can create a gridded dataset of all the data using:\n",
    "\n",
    "```\n",
    "grid_lon = np.arange(-15, 15, 0.5)\n",
    "grid_lat = np.arange(45, 65, 0.5)\n",
    "prof_gridded = analysis.average_into_grid_boxes(grid_lon, grid_lat)\n",
    "```\n",
    "\n",
    "Alternatively, we can calculate averages for each season:\n",
    "\n",
    "```\n",
    "prof_gridded_DJF = profile_analysis.average_into_grid_boxes(grid_lon, grid_lat, season=\"DJF\", var_modifier=\"_DJF\")\n",
    "prof_gridded_MAM = profile_analysis.average_into_grid_boxes(grid_lon, grid_lat, season=\"MAM\", var_modifier=\"_MAM\")\n",
    "prof_gridded_JJA = profile_analysis.average_into_grid_boxes(grid_lon, grid_lat, season=\"JJA\", var_modifier=\"_JJA\")\n",
    "prof_gridded_SON = profile_analysis.average_into_grid_boxes(grid_lon, grid_lat, season=\"SON\", var_modifier=\"_SON\")\n",
    "```\n",
    "\n",
    "Here, `season` specifies which season to average over and `var_modifier` is added to the end of \n",
    "all variable names in the object's dataset. \n",
    "\n",
    "This function returns a new Gridded object. It also contains a new variable\n",
    "called `grid_N`, which stores how many profiles were averaged into each grid box.\n",
    "You may want to use this when using the analysis.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
