[{"body":"An introduction to the COAsT package\u0026rsquo;s NEMO class. In a python window\n1. Load python modules and create some aliases import coast import os import numpy as np import xarray as xr import datetime dn_files = \u0026#34;./example_files/\u0026#34; fn_nemo_dat = \u0026#39;COAsT_example_NEMO_data.nc\u0026#39; fn_nemo_dom = \u0026#39;COAsT_example_NEMO_domain.nc\u0026#39; 2. Load the NEMO data, the domain configuration data and blend them Using the NEMO class a output file is read with the domain configuration file and an object is created for all the variables on the specified grid. For example:\nsci = coast.NEMO(dn_files + fn_nemo_dat, dn_files + fn_nemo_dom, grid_ref = \u0026#39;t-grid\u0026#39;) Will create an object called sci with all the t-grid variables. These can be listed:\nsci.dataset Which returns:\n\u0026lt;xarray.Dataset\u0026gt; Dimensions: (axis_nbounds: 2, t_dim: 7, x_dim: 297, y_dim: 375, z_dim: 51) Coordinates: time (t_dim) datetime64[ns] 2007-01-01T11:58:56 ... 2007-01-31T11:58:56 longitude (y_dim, x_dim) float32 ... latitude (y_dim, x_dim) float32 ... depth_0 (z_dim, y_dim, x_dim) float32 0.5 0.5 0.5 ... 50.5 50.5 Dimensions without coordinates: axis_nbounds, t_dim, x_dim, y_dim, z_dim Data variables: deptht_bounds (z_dim, axis_nbounds) float32 ... sossheig (t_dim, y_dim, x_dim) float32 ... time_counter_bounds (t_dim, axis_nbounds) datetime64[ns] ... time_instant (t_dim) datetime64[ns] ... temperature (t_dim, z_dim, y_dim, x_dim) float32 ... e1 (y_dim, x_dim) float32 ... e2 (y_dim, x_dim) float32 ... e3_0 (z_dim, y_dim, x_dim) float32 ... Attributes: name: AMM7_1d_20070101_20070131_25hourm_grid_T description: ocean T grid variables, 25h meaned title: ocean T grid variables, 25h meaned Conventions: CF-1.6 timeStamp: 2019-Dec-26 04:35:28 GMT uuid: 96cae459-d3a1-4f4f-b82b-9259179f95f7 history: Tue May 19 12:07:51 2020: ncks -v votemper,sossheig -d time... NCO: 4.4.7 Along with temperature (which has been renamed from votemper) a number of other things have happen under the hood:\n The dimensions have been renamed to t_dim, x_dim, y_dim, z_dim The coordinates have been renamed to time, longitude, latitude and depth_0. These are the coordinates for this grid (the t-grid). Also depth_0 has been calculated as the 3D depth array at time zero. The variables e1, e2 and e3_0 have been created. These are the metrics for the t-grid in the x-dim, y-dim and z_dim (at time zero) directions.  So we see that the NEMO class has standardised some variable names and created an object based on this discretisation grid by combining the appropriate grid information with all the variables on that grid.\n3. Load multiple files Powered by xarray, the NEMO class can load and merge multiple files:\nfile_names_amm7 = \u0026#34;nemo_data_T_grid*.nc\u0026#34; amm7 = coast.NEMO(dn_files + file_names_amm7, dn_files + fn_nemo_dom, grid_ref=\u0026#39;t-grid\u0026#39;, multiple=True) These are automatically stacked over the appropriate dimension, here time.\n4. Load subset data With NEMO data files can written for spatial subsets of the whole domain. In the NEMO class, when the grid information is extracted for pairing with the variables an appropriate subsetting of the grid information is applied:\nfn_nemo_dat_subset = \u0026#39;COAsT_example_NEMO_subset_data.nc\u0026#39; amm7 = coast.NEMO(dn_files + fn_nemo_dat_subset, dn_files + fn_nemo_dom) ","excerpt":"An introduction to the COAsT package\u0026rsquo;s NEMO class. In a python window\n1. Load python modules …","ref":"/COAsT/docs/examples/intro_nemo_class/","title":"The NEMO class"},{"body":"Here we give a short tutorial of how to use the ALTIMETRY object for reading data and comparing to NEMO data.\nBegin by importing coast and other packages\nimport coast And by defining some file paths. There are the example files that can be obtained with the COAsT package:\nfn_nemo_dat = './example_files/COAsT_example_NEMO_data.nc' fn_nemo_dom = './example_files/COAsT_example_NEMO_domain.nc' fn_altimetry = './example_files/COAsT_example_altimetry_data.nc' We need to load in a NEMO object for doing NEMO things.\nnemo = coast.NEMO(fn_nemo_dat, fn_nemo_dom, grid_ref='t-grid') And now we can load in our ALTIMETRY data. By default, ALTIMETRY is set up to read in CMEMS netCDF files. However, if no path is supplied, then the object\u0026rsquo;s dataset will be initialised as None. Custom data can then be loaded if desired, as long as it follows the data formatting for ALTIMETRY.\naltimetry = coast.ALTIMETRY(fn_altimetry) Before going any further, lets just cut out the bit of the altimetry that is over the model domain. This can be done using subset_indices_lonlat_box to find relevant indices and then isel to extract them. The data has also been thinned slightly.\nind = altimetry.subset_indices_lonlat_box([-10,10], [45,60]) ind = ind[::4] altimetry = altimetry.isel(t_dim=ind) Before comparing our observations to the model, we will interpolate a model variable to the same time and geographical space as the altimetry. This is done using the obs_operator() method:\naltimetry.obs_operator(nemo, mod_var_name='ssh', time_interp='nearest') Doing this has created a new interpolated variable called interp_ssh and saved it back into our ALTIMETRY object. Take a look at altimetry.dataset to see for yourself.\nNext we will compare this interpolated variable to an observed variable using some basic metrics. The basic_stats() routine can be used for this, which calculates some simple metrics including differences, RMSE and correlations. NOTE: This may not be a wise choice of variables.\nstats = altimetry.basic_stats('interp_ssh', 'sla_filtered') Take a look inside stats.dataset to see all of the new variables. When using basic stats, the returned object is also an ALTIMETRY object, so all of the same methods can be applied. Alternatively, if you want to save the new metrics to the original altimetry object, set create_new_object = False.\nNow we will do a more complex comparison using the Continuous Ranked Probability Score (CRPS). For this, we need to hand over the model object, a model variable and an observed variable. We also give it a neighbourhood radius in km (nh_radius).\ncrps = altimetry.crps(nemo, model_var_name = 'ssh', obs_var_name = 'sla_filtered', nh_radius = 20) Again, take a look inside crps.dataset to see some new variables. Similarly to basic_stats, create_new_object can be set to false to save output to the original altimetry object.\nALTIMETRY has a ready built quick_plot() routine for taking a look at any of the observed or derived quantities above. So to take a look at the \u0026lsquo;sla_filtered\u0026rsquo; variable:\nfig, ax = altimetry.quick_plot('sla_filtered') As stats and crps are also ALTIMETRY objects, quick_plot() can also be used:\nfig, ax = crps.quick_plot('crps') fig, ax = stats.quick_plot('absolute_error') ","excerpt":"Here we give a short tutorial of how to use the ALTIMETRY object for reading data and comparing to …","ref":"/COAsT/docs/examples/altimetry/","title":"Altimetry"},{"body":"COAsT (Coastal Ocean Assessment Toolkit) is a diagnostics and assessment python toolbox for kilometric scale regional models. The aim is that this toolbox is community-ready and flexible.\nThe initial focus will be on delivering a limited number of novel diagnostics for NEMO configurations, but that the toolbox would be expanded to include other diagnostics and other ocean models.\n","excerpt":"COAsT (Coastal Ocean Assessment Toolkit) is a diagnostics and assessment python toolbox for …","ref":"/COAsT/docs/overview/","title":"Overview"},{"body":"Python as a language comes with more stringent recommendations than most when it comes to code styling. This is advantageous in our case as it gives us an obvious set of guidelines to adopt.\nWhen it comes to simple code styling, much of what\u0026rsquo;s recommended here will be copied from Python Enhancement Proposal (PEP) 8, an officially proposed and accepted Python style guide.\nCode Styling Conventions Let\u0026rsquo;s keep things simple to start with\u0026hellip;\n  Indentation should be achieved with spaces rather than tabs and each new level of indentation should be indented by four columns (i.e four spaces).\n  Any single line, including its indentation characters, should not exceed 79 characters in length.\n  Top-level (i.e at the module/file level rather than inside a function or class) function and class definitions should be separated by two blank lines.\n  Method (functions within a class) definitions are separated by a single blank line.\n  Usually, \u0026ldquo;import\u0026rdquo; statements should be on separate lines, that is to say that you should have one line per distinct module or package import. An exception to this rule is when multiple objects are imported from a single module or package, using a \u0026ldquo;from\u0026rdquo; statement, in which case individual objects can be imported on the same line, separated by commas.\n  PEP 8 does not make a recommendation relating to the use of double or single quotes in general use, but for the sake of consistency, this document suggests the use of double quotes wherever practical. This recommendation is intended for the sake of consistency with triple-quoted strings, as per Docstring Conventions (PEP 257).\n  Operators should be separated by single columns (i.e one space) either side, unless inside parentheses, in which case no whitespace is required.\n  Comments (beginning with the # character) should be indented as if they were code. In the case of inline comments, separate the comment with two spaces following the code it shares the line with.\n  All functions should contain a docstring, which provides basic information on its usage. For this project, the reStructuredText docstring format is suggested.\n  When it comes to naming variables and functions, snake case (lower_case_words_separated_by_underscores) is preferred. There are however a few exceptions to this rule: Class names should be styled as camel case (EveryNewWordIsCapitalised). Constants (Variables that should not be changed) can be indicated by the use of screaming snake case (UPPER_CASE_WORDS_SEPARATED_BY_UNDERSCORES). Note that this library currently targets Python 3.7, so the use of typing.Final official support for constant variables, new as of Python 3.8: is not currently supported.\n  In general, it is suggested to avoid the use of single-character variable names, but this is acceptable in certain cases, such as when defining coordinates (such as x, y and z), as these will be commonly recognized and enforcing different rules could cause confusion. PEP 8 advises the following regarding names to avoid: \u0026ldquo;Never use the characters \u0026lsquo;l\u0026rsquo; (lowercase letter el), \u0026lsquo;O\u0026rsquo; (uppercase letter oh), or \u0026lsquo;I\u0026rsquo; (uppercase letter eye) as single character variable names.\u0026rdquo; These specific characters should be avoided because they present an accessibility issue, as under many fonts these characters may be difficult to distinguish or completely indistinguishable from numerals one (1) and zero (0).\n  In the interest of readability, where named iterator variables are required, this document suggests the use of double characters (e.g. \u0026ldquo;ii\u0026rdquo; rather than \u0026ldquo;i\u0026rdquo;).\n  Object-Oriented Programming The general principles of OOP are fairly straightforward and well documented, so I won\u0026rsquo;t waste your precious time by regurgitating that particular wall of text here. Instead, I\u0026rsquo;ll focus on some general pointers specific to this language and use case.\n  In Python, all class attributes are technically public, but semantically, attributes can be designated as non-public by including leading underscores in the name. For instance, \u0026ldquo;my_variable\u0026rdquo; becomes \u0026ldquo;_my_variable\u0026rdquo;. These attributes are generally referred to as \u0026ldquo;protected\u0026rdquo;.\n  When you define a Python class, it is a best practice to inherit from the base object type. This convention stems from Python 2.X, as classes and types were not originally synonymous. This behaviour is implicit in Python 3.X but the convention has persisted nonetheless. Classes defined this way are referred to as \u0026ldquo;new-style\u0026rdquo; classes.\n  When defining a class that inherits from another, it is important to remember that overridden methods (in particular, this behaviour is important when dealing with __init__ methods) do not implicitly call the parent method. What this means is that unless you want to deliberately prevent the behaviour of the parent class (this is a very niche use-case), it is important to include a reference to the parent method. An example of this is: super().__init__() This functionality is advantageous as it prevents unnecessary duplication of code, which is a key tenet of object-oriented software.\n  ","excerpt":"Python as a language comes with more stringent recommendations than most when it comes to code …","ref":"/COAsT/docs/contributing_package/python_style/","title":"Python: Style"},{"body":"This is a demonstration script for using the TIDEGAUGE object in the COAsT package. This object has strict data formatting requirements, which are outlined in TIDEGAUGE.py.\nBegin by importing coast and other packages\nimport coast import datetime And by defining some file paths from the COAsT example files\nfn_nemo_dat = './example_files/COAsT_example_NEMO_data.nc' fn_nemo_dom = './example_files/COAsT_example_NEMO_domain.nc' fn_tidegauge = './example_files/tide_gauges/lowestoft-p024-uk-bodc' fn_tidegauge_mult = './example_files/tide_gauges/l*' We need to load in a NEMO object for doing NEMO things.\nnemo = coast.NEMO(fn_nemo_dat, fn_nemo_dom, grid_ref='t-grid') And now we can load in our ALTIMETRY data. By default, TIDEGAUGE is set up to read in GESLA ASCII files. However, if no path is supplied, then the object\u0026rsquo;s dataset will be initialised as None. Custom data can then be loaded if desired, as long as it follows the data formatting for TIDEGAUGE. Here we load data between two specified dates:\ndate0 = datetime.datetime(2007,1,10) date1 = datetime.datetime(2007,1,12) tidegauge = coast.TIDEGAUGE(fn_tidegauge, date_start = date0, date_end = date1) Before comparing our observations to the model, we will interpolate a model variable to the same time and geographical space as the tidegauge. This is done using the obs_operator() method:\ntidegauge.obs_operator(nemo, mod_var_name='ssh', time_interp='nearest') Doing this has created a new interpolated variable called interp_ssh and saved it back into our TIDEGAUGE object. Take a look at tidegauge.dataset to see for yourself.\nNext we will compare this interpolated variable to an observed variable using some basic metrics. The basic_stats() routine can be used for this, which calculates some simple metrics including differences, RMSE and correlations. NOTE: This may not be a wise choice of variables.\nstats = tidegauge.basic_stats('interp_ssh', 'sea_level') Take a look inside stats.dataset to see all of the new variables. When using basic stats, the returned object is also an TIDEGAUGE object, so all of the same methods can be applied. Alternatively, if you want to save the new metrics to the original TIDEGAUGE object, set create_new_object = False.\nNow we will do a more complex comparison using the Continuous Ranked Probability Score (CRPS). For this, we need to hand over the model object, a model variable and an observed variable. We also give it a neighbourhood radius in km (nh_radius).\ncrps = tidegauge.crps(nemo, model_var_name = 'ssh', obs_var_name = 'sea_level', nh_radius = 20) Again, take a look inside crps.dataset to see some new variables. Similarly to basic_stats, create_new_object can be set to false to save output to the original tidegauge object.\nTIDEGAUGE has ready made quick plotting routines for viewing time series and tide gauge location. To look at the tide gauge location:\nfig, ax = tidegauge.plot_on_map() Or to look at a time series of the sea_level variable:\nfig, ax = tidegauge.plot_timeseries('sea_level', qc_colors=True) Note that start and end dates can also be specified for plot_timeseries().\nAs stats and crps are also TIDEGAUGE objects, the same time series plotting functionality can be used:\ncrps.plot_timeseries('crps') stats.plot_timeseries('absolute_error') Each TIDEGAUGE object only holds data for a single tidegauge. There is some functionality for dealing with multiple gauges in COAsT. To load multiple GESLA tidegauge files, we use the static method create_multiple_tidegauge(). This routine takes a list of files or a wildcard string and loads them all into a list of TIDEGAUGE objects.\nfrom coast.TIDEGAUGE import TIDEGAUGE date0 = datetime.datetime(2007,1,10) date1 = datetime.datetime(2007,1,12) tidegauge_list = TIDEGAUGE.create_multiple_tidegauge(fn_tidegauge_mult, date0,date1) Now that we have tidegauge_list, we can plot the locations of all tide gauges as follows:\nfig, ax = TIDEGAUGE.plot_on_map_multiple(tidegauge_list) To do analysis on multiple gauges, a simple looping script can be setup. For example, to obtain basic stats:\nfor tg in tidegauge_list: tg.obs_operator(nemo, 'ssh') tg.basic_stats('interp_ssh', 'sea_level', create_new_object=False) And now some of these new values can be plotted on a map, again using plot_on_map_multiple:\nfig, ax = TIDEGAUGE.plot_on_map_multiple(tidegauge_list, color_var_str='rmse') ","excerpt":"This is a demonstration script for using the TIDEGAUGE object in the COAsT package. This object has …","ref":"/COAsT/docs/examples/tidegauge/","title":"Tidegauge"},{"body":"Coming soon\u0026hellip;\n","excerpt":"Coming soon\u0026hellip;","ref":"/COAsT/docs/examples/transect/","title":"Transect analysis"},{"body":"Prerequisites This package requires;\n python version 3.7+ Anaconda version 3.7  Are there any system requirements for using your project? What languages are supported (if any)? Do users need to already have any software or tools installed?\nInstallation This package should be installed by run;\nconda install -c conda-forge -c bodc coast However, there is also the option of;\npip install COAsT if you wish to install from source then got to GitHub and follow the README instructions\nSetup The base package should now be installed on your system. The following packages might be required for some of the advanced features;\n cartopy graphviz  Try it out! The below example works best with the COAsT example data. Start by importing COAsT:\nimport coast Now load a NEMO output file and domain file into a NEMO object (specifying the grid):\ndata_file = \u0026#39;\u0026lt;Path to NEMO data file\u0026gt;\u0026#39; domain_file = \u0026#39;\u0026lt;Path to NEMO domain file\u0026gt;\u0026#39; sci = coast.NEMO(data_file, domain_file, grid_ref = \u0026#39;t-grid\u0026#39;) You can now start having a look at some of the methods inside the NEMO class. Interrogate the NEMO data by taking a look inside sci.dataset. This contains all the information from the netCDF file.\nLets take a look at some altimetry data around the UK too. Load in the data:\naltimetry_file = \u0026#39;\u0026lt;Path to Altimetry data file\u0026gt;\u0026#39; altimetry = coast.ALTIMETRY(altimetry_file) Subset the data so that only data over the North West European Shelf remains in the object.\nind = altimetry.subset_indices_lonlat_box([-10,10], [45,60]) altimetry = altimetry.isel(t_dim=ind) Now take a look at the data inside the object:\naltimetry.quick_plot('sla_filtered') Nice one! Hopefully that all worked and you\u0026rsquo;re ready to take a look at the rest of the package and documentation. Take a look at the example pages for more information on specific objects and methods.\n","excerpt":"Prerequisites This package requires;\n python version 3.7+ Anaconda version 3.7  Are there any system …","ref":"/COAsT/docs/getting-started/","title":"Getting Started"},{"body":"** Notes on Object Structure and Loading (for contributors):\nCOAsT is an object-orientated package, meaning that data is stored within Python object structures. In addition to data storage, these objects contain methods (subroutines) which allow for manipulation of this data. An example of such an object is the NEMO object, which allows for the storage and manipulation of NEMO output and domain data. It is important to understand how to load data using COAsT and the structure of the resulting objects.\nA NEMO object is created and initialised by passing it the paths of the domain and data files. Ideally, the grid type should also be specified (T, U, V or F in the case of NEMO). For example, to load in data from a file containing data on a NEMO T-grid:\nimport coast fn_data = '\u0026lt;path to T-grid data file(s)\u0026gt;' fn_domain = '\u0026lt;path to domain file\u0026gt;' data = coast.NEMO(fn_data, fn_domain, grid_ref='t-grid') Ideally, NEMO output data should be in grid-specific files, i.e. containing output variables situated on a NEMO T, U, V or F grid. The whole domain file is supplied, however only grid specific variables are placed into the NEMO object. A NEMO object therefore contains grid-specific data and all corresponding grid variables. One of the file names can beomitted (to get a data-only or grid only object), however functionality in this case will be limited.\nOnce loaded, data is stored inside the object using an xarray.dataset object. Following on from the previous code example, this can be viewed by calling:\ndata.dataset This reveals all netcdf-type aspects of the data and domain variables that were loaded, including dimensions, coordinates, variables and attributes. For example:\n\u0026lt;xarray.Dataset\u0026gt; Dimensions: (axis_nbounds: 2, t_dim: 7, x_dim: 297, y_dim: 375, z_dim: 51) Coordinates: time (t_dim) datetime64[ns] 2007-01-01T11:58:56 ... 2007-01-31T11:58:56 longitude (y_dim, x_dim) float32 ... latitude (y_dim, x_dim) float32 ... Dimensions without coordinates: axis_nbounds, t_dim, x_dim, y_dim, z_dim Data variables: deptht_bounds (z_dim, axis_nbounds) float32 ... sossheig (t_dim, y_dim, x_dim) float32 ... time_counter_bounds (t_dim, axis_nbounds) datetime64[ns] ... time_instant (t_dim) datetime64[ns] ... temperature (t_dim, z_dim, y_dim, x_dim) float32 ... e1 (y_dim, x_dim) float32 ... e2 (y_dim, x_dim) float32 ... e3_0 (z_dim, y_dim, x_dim) float32 1.0 1.0 1.0 ... 1.0 1.0 Variables may be obtained in a number of ways. For example, to get temperature data, the following are all equivalent:\ntemp = data.dataset.temperature temp = data.dataset['temperature'] temp = data['temperature'] These commands will all return an xarray.dataarray object. Manipulation of this object can be done using xarray commands, for example indexing using [] or xarray.isel. Be aware that indexing will preserve lazy loading, however and direct access or modifying of the data will not. For this reason, if you require a subset of the data, it is best to index first.\nThe names of common grid variables are standardised within the COAsT package for consistency and ease of use. Along with their original NEMO names, these are:\n longitude [glamt / glamu / glamv / glamf] latitude [gphit / gphiu / gphiv / gphif] time [time_counter] e1 [e1t / e1u / e1v / e1f] (dx variable) e2 [e1t / e1u / e1v / e1f] (dy variable) e3_0 [e3t_0 / e3u_0 / e3v_0 / e3f_0] (dz variable at time 0)  Longitude, latitude and time are also set as coordinates. You might notice that dimensions are also standardised:\n x_dim The dimension for the x-axis (longitude) y_dim The dimension for the y-axis (latitude) t_dim The dimension for the time axis z_dim The dimension for the depth axis.  Wherever possible, the aim is to ensure that all of the above is consistent across the whole COAsT toolbox. Therefore, you will also find the same names and dimensions in, for example observation objects. Future objects, where applicable, will also follow these conventions. If you (as a contributor) add new objects to the toolbox, following the above template is strongly encouraged. This includes using xarray dataset/dataarray objects where possible, adopting an object oriented approach and adhering to naming conventions.\n","excerpt":"** Notes on Object Structure and Loading (for contributors):\nCOAsT is an object-orientated package, …","ref":"/COAsT/docs/contributing_package/python_structure/","title":"Python: Structure"},{"body":"A demonstration of pycnocline depth and thickness diagnostics. The first and second depth moments of stratification are computed as proxies for pycnocline depth and thickness, suitable for a nearly two-layer fluid.\nimport coast import numpy as np import os import xarray as xr import dask import matplotlib.pyplot as plt import matplotlib.colors as colors # colormap fiddling Load in the data After downloading the example files and placing the example_files directory in your working directory, set some aliases and load the t-grid data:\n# set some paths config = \u0026#39;AMM7\u0026#39; dn_files = \u0026#34;./example_files/\u0026#34; dn_fig = \u0026#34;\u0026#34; # somewhere to put the figures fn_nemo_grid_t_dat = \u0026#39;nemo_data_T_grid_Aug2015.nc\u0026#39; fn_nemo_dom = \u0026#39;COAsT_example_NEMO_domain.nc\u0026#39; sci_t = coast.NEMO(dn_files + fn_nemo_grid_t_dat, dn_files + fn_nemo_dom, grid_ref=\u0026#39;t-grid\u0026#39;, multiple=True) The stratification variables are computed as centred differences of the t-grid variables. These will become w-grid variables. So, create an empty w-grid object, to store stratification.\nsci_w = coast.NEMO( fn_domain = dn_files + fn_nemo_dom, grid_ref=\u0026#39;w-grid\u0026#39;) Subset the domain We are not interested in the whole doman so it is computationally efficient to subset the data for the region of interest. Here we will look at the North Sea between (51N: 62N) and (-4E:15E). We will great subset objects for both the t- and w-grids:\nind_sci = sci_t.subset_indices([51,-4], [62,15]) sci_nwes_t = sci_t.isel(y_dim=ind_sci[0], x_dim=ind_sci[1]) #nwes = northwest european shelf ind_sci = sci_w.subset_indices([51,-4], [62,15]) sci_nwes_w = sci_w.isel(y_dim=ind_sci[0], x_dim=ind_sci[1]) #nwes = northwest european shelf Diagnostic calculations and plotting We can use a COAsT method to construct the in-situ density:\nsci_nwes_t.construct_density( EOS=\u0026#39;EOS10\u0026#39; ) Then we construct stratification using a COAsT method to take the vertical derivative. Noting that the inputs are on t-pts and the outputs are on w-pts\nsci_nwes_w = sci_nwes_t.differentiate( \u0026#39;density\u0026#39;, dim=\u0026#39;z_dim\u0026#39;, out_varstr=\u0026#39;rho_dz\u0026#39;, out_obj=sci_nwes_w ) # --\u0026gt; sci_nwes_w.rho_dz This has created a variable called sci_nwes_w.rho_dz.\nWe can now use the INTERNALTIDE class to construct the first and second moments (over depth) of density. In the limit of an idealised two-layer fluid these converge to the depth and thickness of the interface. I.e. the pycnocline depth and thickness respectively.\n#%% Create internal tide diagnostics object IT = coast.INTERNALTIDE(sci_nwes_t, sci_nwes_w) #%% Construct pycnocline variables: depth and thickness IT.construct_pycnocline_vars( sci_nwes_t, sci_nwes_w ) Finally we plot pycnocline variables (depth and thickness) using an INTERNALTIDES method:\nIT.quick_plot() for example the pycnocline depth map. In the interest of simplicity, unstratified areas are masked (this includes the land):  \n","excerpt":"A demonstration of pycnocline depth and thickness diagnostics. The first and second depth moments of …","ref":"/COAsT/docs/examples/stratification/","title":"Stratification diagnostics"},{"body":"The Github page for this package can be found here\nThe rest of this page is coming soon.\n","excerpt":"The Github page for this package can be found here\nThe rest of this page is coming soon.","ref":"/COAsT/docs/contributing-docs/github_workflow/","title":"Github Workflow"},{"body":"COAsT utilises Python’s default logging library and includes a simple setup function for those unfamiliar with how to use it.\nimport coast coast.logging_util.setup_logging() This is all you need to enable full logging output to the console.\nBy default, setup_logging will use the \u0026ldquo;DEBUG\u0026rdquo; logging level, if you want to adjust this, you can use the flags from the logging library.\nimport coast import logging coast.logging_util.setup_logging(level=logging.INFO) Alternative logging levels in increasing levels of severity. Note logs are reported at the chosen severity level and higher:\n..., level=logging.DEBUG) # Detailed information, typically of interest only when diagnosing problems. ..., level=logging.INFO) # Confirmation that things are working as expected. ..., level=logging.WARNING) # An indication that something unexpected happened, or indicative of some problem in the near future (e.g. ‘disk space low’). The software is still working as expected. ..., level=logging.ERROR) # Due to a more serious problem, the software has not been able to perform some function ..., level=logging.CRITICAL) # A serious error, indicating that the program itself may be unable to continue running For more info on logging levels, see the relevant Python documentation.\nLogging output will be printed in the console once enabled by default, but output can be directed to any Stream, for instance, to an opened file.\nimport coast file = open(\u0026#34;coast.log\u0026#34;, \u0026#34;w\u0026#34;) coast.logging_util.setup_logging(stream=file) coast.logging_util.info(\u0026#34;Hello World!\u0026#34;) # Your use of COAsT would go here, this line is included as an example file.close() ","excerpt":"COAsT utilises Python’s default logging library and includes a simple setup function for those …","ref":"/COAsT/docs/contributing_package/python_logging/","title":"Logging"},{"body":"Example data are provided for the following tutorial. Download these files and place the example_files directory in your working directory.\nThe following tutorial is split into sections:\n","excerpt":"Example data are provided for the following tutorial. Download these files and place the …","ref":"/COAsT/docs/examples/","title":"Examples"},{"body":"Here you will find information needed to contribute code changes to the COAsT package.\n","excerpt":"Here you will find information needed to contribute code changes to the COAsT package.","ref":"/COAsT/docs/contributing_package/","title":"Contributing: COAsT"},{"body":"We use Hugo Extended Version to format and generate our website, the Docsy theme for styling and site structure, and GitHub pages to manage the deployment of the site. Hugo is an open-source static site generator that provides us with templates, content organisation in a standard directory structure, and a website generation engine. You write the pages in Markdown (or HTML if you want), and Hugo wraps them up into a website.\nAll submissions, including submissions by project members, require review. We use GitHub pull requests for this purpose. Consult GitHub Help for more information on using pull requests.\nUpdating a single page If you\u0026rsquo;ve just spotted something you\u0026rsquo;d like to change while using the docs, Docsy has a shortcut for you:\n Click Edit this page in the top right hand corner of the page. If you don\u0026rsquo;t already have an up to date fork of the project repo, you are prompted to get one - click Fork this repository and propose changes or Update your Fork to get an up to date version of the project to edit. The appropriate page in your fork is displayed in edit mode. make your edit submit a pull request with a summary of the changes  Previewing your changes locally If you want to run your own local Hugo server to preview your changes as you work:\n  Follow the instructions in Getting started to install Hugo and any other tools you need. You\u0026rsquo;ll need at least Hugo version 0.45 (we recommend using the most recent available version), and it must be the extended version, which supports SCSS.\n  Fork the COAsT-site repo repo into your own project, then create a local copy using git clone. Don’t forget to use --recurse-submodules or you won’t pull down some of the code you need to generate a working site.\ngit clone --recurse-submodules --depth 1 https://github.com/British-Oceanographic-Data-Centre/COAsT-site.git   Run npm install to install Node.js dependencies.\n  Run hugo server in the site root directory. By default your site will be available at http://localhost:1313/COAsT. Now that you\u0026rsquo;re serving your site locally, Hugo will watch for changes to the content and automatically refresh your site.\n  Continue with the usual GitHub workflow to edit files, commit them, push the changes up to your fork, and create a pull request.\n  Creating an issue If you\u0026rsquo;ve found a problem in the docs, but you\u0026rsquo;re not sure how to fix it yourself, please create an issue in the COAsT-site repo. You can also create an issue about a specific page by clicking the Create Issue button in the top right hand corner of the page.\nUseful resources  Docsy user guide: All about Docsy, including how it manages navigation, look and feel, and multi-language support. Hugo documentation: Comprehensive reference for Hugo. Github Hello World!: A basic introduction to GitHub concepts and workflow.  ","excerpt":"We use Hugo Extended Version to format and generate our website, the Docsy theme for styling and …","ref":"/COAsT/docs/contributing-docs/","title":"Contributing: Documentation"},{"body":"What is lazy\u0026hellip; \u0026hellip;loading Lazy loading determines if data is read into memory straight away (on that line of code execution) or if the loading is delayed until the data is physical altered by some function (normally mathematical in nature)\n\u0026hellip;evaluation Lazy evaluation is about delaying the execution of a method/function call until the value is physical required, normally as a graph or printed to screen. Lazy evaluation can also help with memory management, useful with large dataset, by allowing for optimisation on the chained methods calls.\nLazy loading and Lazy evaluation are offer used together, though it is not mandatory and always worth checking that both are happening.\nBeing Lazy in COAsT There are two way to be Lazy within the COAsT package.\n xarray Dask  xarray COAsT uses xarray to load NetCDF files in, by default this will be Lazy, the raw data values will not be brought into memory.\nyou can slice and subset the data while still having the lazy loading honoured, it is not until the data is altered, say via a call to NumPy.cumsum, that the required data will be loaded into memory.\nNote the data on disk (in the NetCDF file) is never altered, only the values in memory are changed.\nimport xarray as xr import NumPy as np dataset_domain = xr.open_dataset(fn_domain) e3w_0 = dataset_domain.e3w_0 # still lazy loaded e3w_0_cs = np.cumsum(e3w_0[1:, :, :], axis=0) # now in memory Dask When in use Dask will provide lazy evaluation on top of the lazy loading.\nusing the same example as above, a file loaded in using xarray, this time with the chunks option set, will not only lazy load the data, but will turn on Dask, now using either the xarray or Dask wrapper functions will mean the NumPy cumsum call is not evaluated right way, in fact it will not be evaluated until either the compute function is called, or a greedy method from another library is used.\nimport xarray as xr dataset_domain = xr.open_dataset(fn_domain, chunks={\u0026#34;t\u0026#34;: 1}) e3w_0 = dataset_domain.e3w_0 # still lazy loaded e3w_0_cs = e3w_0[1:, :, :].cumsum(axis=0) # Dask backed Lazy evaluation We discuss Dask even more here.\n","excerpt":"What is lazy\u0026hellip; \u0026hellip;loading Lazy loading determines if data is read into memory straight …","ref":"/COAsT/docs/contributing_package/lazy-loading/","title":"working Lazily"},{"body":"What is Dask Dask is a python library that allows code to be run in parallel based on the hardware your running on. This means Dask works just as well on your laptop as on your large server.\nUsing Dask Dask is included in the xarray library, when loading a data source (file/NumPy array) you can turn Dask on by setting the chunks variable\nnemo_t = coast.NEMO( fn_data=dn_files+fn_nemo_grid_t_dat, fn_domain=dn_files+fn_nemo_dom, grid_ref=\u0026#39;t-grid\u0026#39;, chunks={\u0026#34;time_counter\u0026#34;:3}) chunks tell Dask where to break your data across the different processor tasks.\nDirect Dask Dask can be imported and used directly\nimport Dask.array as da big_array = da.multiple(array1,array2) Dask arrays follow the NumPy API. This means that most NumPy functions have a Dask version.\nPotential Issues Dask objects are immutable. This means that the classic approach, pre-allocation follow by modification will not work.\nThe following code will error.\nimport Dask.array as da e3w_0 = da.squeeze(dataset_domain.e3w_0) depth_0 = da.zero_like(e3w_0) depth_0[0, :, :] = 0.5 * e3w_0[0, :, :] # this line will error out option 1 Continue using NumPy function but wrapping the final value in a Dask array. This final Dask object will still be in-memory.\ne3w_0 = np.squeeze(dataset_domain.e3w_0) depth_0 = np.zeros_like(e3w_0) depth_0[0, :, :] = 0.5 * e3w_0[0, :, :] depth_0[1:, :, :] = depth_0[0, :, :] + np.cumsum(e3w_0[1:, :, :], axis=0) depth_0 = da.array(depth_0) option 2 Dask offers a feature called delayed. This can be used as a modifier on your complex methods as follows;\n@Dask.delayed def set_timezero_depths(self, dataset_domain): # complex workings these do not return the computed answer, rather it returns a delayed object. These delayed object get stacked, as more delayed methods are called. When the value is needed, it can be computed like so;\nne = coast.NEMO(...) # come complex delayed methods called ne.data_variable.compute() Dask will now work out a computing path via all the required methods using as many processor tasks as possible.\nVisualising the Graph Dask is fundamentally a computational graph library, to understand what is happening in the background it can help to see these graphs (on smaller/simpler problems). This can be achieved by running;\nne = coast.NEMO(...) # come complex delayed methods called ne.data_variable.visualize() this will output a png image of the graph in the calling directory and could look like this;\n  ","excerpt":"What is Dask Dask is a python library that allows code to be run in parallel based on the hardware …","ref":"/COAsT/docs/contributing_package/dask/","title":"Dask"},{"body":"This page will walk you though a simple setup for hugo extended - which is needed if want to view any changes you make to this site locally.\nFor more details please read this.\nInstallation Manual  Download hugo extended from GitHub Unzip into preferred location (I use C:\\hugo) Add to OS PATH  optional but makes usage easier    Via a Package Manager On Windows you can use Chocolately to install with:\nchoco install hugo-extended Or on macOS/Linux you can use Homebrew to install with:\nbrew install hugo Try it out! You should now be able to try the following in a terminal\n$ hugo --help if you have cloned the COAsT-site repo you should also now be able to;\n$ cd COAsT-site $ hugo server the above will start a local hugo powered version of the website. you can edit any of the files under /content and see your changes at http://localhost:1313/COAsT/\n","excerpt":"This page will walk you though a simple setup for hugo extended - which is needed if want to view …","ref":"/COAsT/docs/contributing-docs/hugo/","title":"setting up Hugo"},{"body":"","excerpt":"","ref":"/COAsT/docs/reference/","title":"Reference"},{"body":"Code functionality tests are written in unit_testing/unit_testing.py in the COAsT repository, and therefore contain working examples of the package. These are written to verify the package functionality and to maintain operability following code updates.\nAt the time of writing these included:\n1. Loading \u0026amp; Initialisation a. Loading NEMO data file b. Loading Altimetry file c. Load data from existing dataset d. Set NEMO variable name e. Set NEMO grid attribute - dimension names f. Load only Domain g. Calculate depth_0 for t,u,v,w,f grids h. Load NEMO that is a subregion in the domain file i. Multi load (over time) for NEMO files  2. General Utility Methods in COAsT a. Copying a COAsT object b. COAsT ``__getitem__`` returns variable c. Renaming variables inside a COAsT object  3. Diagnostic Methods a. Compute vertical spatial derivative b. Construct density method inside NEMO class c. Construct pycnocline depth and thickness d. Plot pycnocline depth  4. Transect Methods a. Determine and extract transect indices b. Transport velocity and depth calculations c. Transport and velocity plotting d. Contrust density on z-levels along the transect. Compare with item 3b. e. Geostrophic velocity \u0026amp; transport calculations  5. Object Manipulation (e.g. indexing, subsetting) a. Subsetting single variable b. Indices by distance c. Subsetting entire COAsT object and return as copy d. Find nearest xy indices e. ``NEMO.interpolate_in_space()`` f. ``NEMO.interpolate_in_time()``  6. Validation Methods a. Calculate single obs CRPS values using different methods b. CRPS map plot c. CRPS CDF plot d. Interpolate model to altimetry  7. Plotting Methods a. Altimetry ``quick_plot()`` b. Open, view and save tide gauge data from GESLA database  ","excerpt":"Code functionality tests are written in unit_testing/unit_testing.py in the COAsT repository, and …","ref":"/COAsT/docs/examples/unit_testing/","title":"Unit testing"},{"body":"AMM15 - 1.5km resolution Atlantic Margin Model \u0026#34;\u0026#34;\u0026#34; AMM15_example_plot.py Make simple AMM15 SST plot. \u0026#34;\u0026#34;\u0026#34; #%% import coast import numpy as np import xarray as xr import matplotlib.pyplot as plt import matplotlib.colors as colors # colormap fiddling ################################################# #%% Loading data ################################################# config = \u0026#39;AMM15\u0026#39; dir_nam = \u0026#34;/projectsa/NEMO/gmaya/2013p2/\u0026#34; fil_nam = \u0026#34;20130415_25hourm_grid_T.nc\u0026#34; dom_nam = \u0026#34;/projectsa/NEMO/gmaya/AMM15_GRID/amm15.mesh_mask.cs3x.nc\u0026#34; sci_t = coast.NEMO(dir_nam + fil_nam, dom_nam, grid_ref=\u0026#39;t-grid\u0026#39;, multiple=False) # create an empty w-grid object, to store stratification sci_w = coast.NEMO( fn_domain = dom_nam, grid_ref=\u0026#39;w-grid\u0026#39;) print(\u0026#39;* Loaded \u0026#39;,config, \u0026#39; data\u0026#39;) ################################################# #%% subset of data and domain ## ################################################# # Pick out a North Sea subdomain print(\u0026#39;* Extract North Sea subdomain\u0026#39;) ind_sci = sci_t.subset_indices([51,-4], [62,15]) sci_nwes_t = sci_t.isel(y_dim=ind_sci[0], x_dim=ind_sci[1]) #nwes = northwest europe shelf ind_sci = sci_w.subset_indices([51,-4], [62,15]) sci_nwes_w = sci_w.isel(y_dim=ind_sci[0], x_dim=ind_sci[1]) #nwes = northwest europe shelf #%% Apply masks to temperature and salinity if config == \u0026#39;AMM15\u0026#39;: sci_nwes_t.dataset[\u0026#39;temperature_m\u0026#39;] = sci_nwes_t.dataset.temperature.where( sci_nwes_t.dataset.mask.expand_dims(dim=sci_nwes_t.dataset[\u0026#39;t_dim\u0026#39;].sizes) \u0026gt; 0) sci_nwes_t.dataset[\u0026#39;salinity_m\u0026#39;] = sci_nwes_t.dataset.salinity.where( sci_nwes_t.dataset.mask.expand_dims(dim=sci_nwes_t.dataset[\u0026#39;t_dim\u0026#39;].sizes) \u0026gt; 0) else: # Apply fake masks to temperature and salinity sci_nwes_t.dataset[\u0026#39;temperature_m\u0026#39;] = sci_nwes_t.dataset.temperature sci_nwes_t.dataset[\u0026#39;salinity_m\u0026#39;] = sci_nwes_t.dataset.salinity #%% Plots fig = plt.figure() plt.pcolormesh( sci_t.dataset.longitude, sci_t.dataset.latitude, sci_t.dataset.temperature.isel(z_dim=0).squeeze()) #plt.xlabel(\u0026#39;longitude\u0026#39;) #plt.ylabel(\u0026#39;latitude\u0026#39;) #plt.colorbar() plt.axis(\u0026#39;off\u0026#39;) plt.show() fig.savefig(\u0026#39;AMM15_SST_nocolorbar.png\u0026#39;, dpi=120)    India subcontinent maritime domain. WCSSP India configuration #%% import coast import numpy as np import xarray as xr import dask import matplotlib.pyplot as plt import matplotlib.colors as colors # colormap fiddling ################################################# #%% Loading data ################################################# dir_nam = \u0026#34;/projectsa/COAsT/NEMO_example_data/MO_INDIA/\u0026#34; fil_nam = \u0026#34;ind_1d_cat_20180101_20180105_25hourm_grid_T.nc\u0026#34; dom_nam = \u0026#34;domain_cfg_wcssp.nc\u0026#34; sci_t = coast.NEMO(dir_nam + fil_nam, \\ dir_nam + dom_nam, grid_ref=\u0026#39;t-grid\u0026#39;, multiple=False) #%% Plot fig = plt.figure() plt.pcolormesh( sci_t.dataset.longitude, sci_t.dataset.latitude, sci_t.dataset.temperature.isel(t_dim=0).isel(z_dim=0)) plt.xlabel(\u0026#39;longitude\u0026#39;) plt.ylabel(\u0026#39;latitude\u0026#39;) plt.title(\u0026#39;WCSSP India SST\u0026#39;) plt.colorbar() plt.show() fig.savefig(\u0026#39;WCSSP_India_SST.png\u0026#39;, dpi=120)    South East Asia, 1/12 deg configuration (ACCORD: SEAsia_R12) #%% import coast import numpy as np import xarray as xr import dask import matplotlib.pyplot as plt import matplotlib.colors as colors # colormap fiddling ################################################# #%% Loading data ################################################# dir_nam = \u0026#34;/projectsa/COAsT/NEMO_example_data/SEAsia_R12/\u0026#34; fil_nam = \u0026#34;SEAsia_R12_5d_20120101_20121231_gridT.nc\u0026#34; dom_nam = \u0026#34;domain_cfg_ORCA12_adj.nc\u0026#34; sci_t = coast.NEMO(dir_nam + fil_nam, \\ dir_nam + dom_nam, grid_ref=\u0026#39;t-grid\u0026#39;, multiple=False) #%% Plot fig = plt.figure() plt.pcolormesh( sci_t.dataset.longitude, sci_t.dataset.latitude, sci_t.dataset.soce.isel(t_dim=0).isel(z_dim=0)) plt.xlabel(\u0026#39;longitude\u0026#39;) plt.ylabel(\u0026#39;latitude\u0026#39;) plt.title(\u0026#39;SE Asia, surface salinity (psu)\u0026#39;) plt.colorbar() plt.show() fig.savefig(\u0026#39;SEAsia_R12_SSS.png\u0026#39;, dpi=120)    ","excerpt":"AMM15 - 1.5km resolution Atlantic Margin Model \u0026#34;\u0026#34;\u0026#34; AMM15_example_plot.py Make simple …","ref":"/COAsT/docs/examples/configs_gallery/","title":"Configuration Gallery"},{"body":"__________________________________________________________________________________________ ______ ___ _ _________ .' ___ | .' `. / \\ | _ _ | / .' \\_|/ .-. \\ / _ \\ .--.|_/ | | \\_| | | | | | | / ___ \\ ( (`\\] | | \\ `.___.'\\\\ `-' /_/ / \\ \\_ `'.'. _| |_ `.____ .' `.___.'|____| |____|[\\__) )|_____| Coastal Ocean Assessment Toolbox https://www.nemo-ocean.eu/ Version 0.2.1a10 (alpha build) __________________________________________________________________________________________ COAsT is a Python package for managing and analysing high resolution NEMO output. Here you can find information on obtaining, installing and using COAsT as well as guidelines for contributing to the project.\nThis documentation site is still under construction but you can still find guidelines for contributing to the package and this website. See below for description of each section.\n","excerpt":"__________________________________________________________________________________________ ______ …","ref":"/COAsT/docs/","title":"Documentation"},{"body":"","excerpt":"","ref":"/COAsT/docs/reference/parameter-reference/","title":"Parameter Reference"},{"body":"  #td-cover-block-0 { background-image: url(/COAsT/about/featured-background_hu14d69772da4446f8c45afbc4cad362c8_132726_960x540_fill_q75_catmullrom_top.jpg); } @media only screen and (min-width: 1200px) { #td-cover-block-0 { background-image: url(/COAsT/about/featured-background_hu14d69772da4446f8c45afbc4cad362c8_132726_1920x1080_fill_q75_catmullrom_top.jpg); } }  About COAsT A site using the Docsy Hugo theme. --        COAsT is a Python package for managing and analysing high resolution NEMO output Read more here     This site was based off the Docsy Hugo theme.    ","excerpt":"  #td-cover-block-0 { background-image: …","ref":"/COAsT/about/","title":"About Goldydocs"},{"body":"  #td-cover-block-0 { background-image: url(/COAsT/featured-background_hu14d69772da4446f8c45afbc4cad362c8_132726_960x540_fill_q75_catmullrom_top.jpg); } @media only screen and (min-width: 1200px) { #td-cover-block-0 { background-image: url(/COAsT/featured-background_hu14d69772da4446f8c45afbc4cad362c8_132726_1920x1080_fill_q75_catmullrom_top.jpg); } }  Welcome to the documentation: A Docsy site for COAsT Learn More   Download   COAsT\n\n        This is a single web UI providing visibility into the COAsT python framework.       Download from Anaconda.org Get the COAsT framework!\nRead more …\n   Contributions welcome! We do a Pull Request contributions workflow on GitHub. New users are always welcome!\nRead more …\n   Follow us on Twitter! For announcement of latest features etc.\nRead more …\n    ","excerpt":"#td-cover-block-0 { background-image: …","ref":"/COAsT/","title":"COAsT"},{"body":"","excerpt":"","ref":"/COAsT/community/","title":"Community"},{"body":"","excerpt":"","ref":"/COAsT/search/","title":"Search Results"}]