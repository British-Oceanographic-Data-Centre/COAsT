[{"body":"An introduction to the COAsT package\u0026rsquo;s NEMO class. In a python window\n1. Load python modules and create some aliases import coast import os import numpy as np import xarray as xr import datetime dn_files = \u0026#34;./example_files/\u0026#34; fn_nemo_dat = \u0026#39;COAsT_example_NEMO_data.nc\u0026#39; fn_nemo_dom = \u0026#39;COAsT_example_NEMO_domain.nc\u0026#39; 2. Load the NEMO data, the domain configuration data and blend them Using the NEMO class a output file is read with the domain configuration file and an object is created for all the variables on the specified grid. For example:\nsci = coast.NEMO(dn_files + fn_nemo_dat, dn_files + fn_nemo_dom, grid_ref = \u0026#39;t-grid\u0026#39;) Will create an object called sci with all the t-grid variables. These can be listed:\nsci.dataset Which returns:\n\u0026lt;xarray.Dataset\u0026gt; Dimensions: (axis_nbounds: 2, t_dim: 7, x_dim: 297, y_dim: 375, z_dim: 51) Coordinates: time (t_dim) datetime64[ns] 2007-01-01T11:58:56 ... 2007-01-31T11:58:56 longitude (y_dim, x_dim) float32 ... latitude (y_dim, x_dim) float32 ... depth_0 (z_dim, y_dim, x_dim) float32 0.5 0.5 0.5 ... 50.5 50.5 Dimensions without coordinates: axis_nbounds, t_dim, x_dim, y_dim, z_dim Data variables: deptht_bounds (z_dim, axis_nbounds) float32 ... sossheig (t_dim, y_dim, x_dim) float32 ... time_counter_bounds (t_dim, axis_nbounds) datetime64[ns] ... time_instant (t_dim) datetime64[ns] ... temperature (t_dim, z_dim, y_dim, x_dim) float32 ... e1 (y_dim, x_dim) float32 ... e2 (y_dim, x_dim) float32 ... e3_0 (z_dim, y_dim, x_dim) float32 ... Attributes: name: AMM7_1d_20070101_20070131_25hourm_grid_T description: ocean T grid variables, 25h meaned title: ocean T grid variables, 25h meaned Conventions: CF-1.6 timeStamp: 2019-Dec-26 04:35:28 GMT uuid: 96cae459-d3a1-4f4f-b82b-9259179f95f7 history: Tue May 19 12:07:51 2020: ncks -v votemper,sossheig -d time... NCO: 4.4.7 Along with temperature (which has been renamed from votemper) a number of other things have happen under the hood:\n The dimensions have been renamed to t_dim, x_dim, y_dim, z_dim The coordinates have been renamed to time, longitude, latitude and depth_0. These are the coordinates for this grid (the t-grid). Also depth_0 has been calculated as the 3D depth array at time zero. The variables e1, e2 and e3_0 have been created. These are the metrics for the t-grid in the x-dim, y-dim and z_dim (at time zero) directions.  So we see that the NEMO class has standardised some variable names and created an object based on this discretisation grid by combining the appropriate grid information with all the variables on that grid.\n3. Load multiple files Powered by xarray, the NEMO class can load and merge multiple files:\nfile_names_amm7 = \u0026#34;nemo_data_T_grid*.nc\u0026#34; amm7 = coast.NEMO(dn_files + file_names_amm7, dn_files + fn_nemo_dom, grid_ref=\u0026#39;t-grid\u0026#39;, multiple=True) These are automatically stacked over the appropriate dimension, here time.\n4. Load subset data With NEMO data files can written for spatial subsets of the whole domain. In the NEMO class, when the grid information is extracted for pairing with the variables an appropriate subsetting of the grid information is applied:\nfn_nemo_dat_subset = \u0026#39;COAsT_example_NEMO_subset_data.nc\u0026#39; amm7 = coast.NEMO(dn_files + fn_nemo_dat_subset, dn_files + fn_nemo_dom) ","excerpt":"An introduction to the COAsT package\u0026rsquo;s NEMO class. In a python window\n1. Load python modules …","ref":"/COAsT/docs/examples/intro_nemo_class/","title":"The NEMO class"},{"body":"COAsT (Coastal Ocean Assessment Toolkit) is a diagnostics and assessment python toolbox for kilometric scale regional models. The aim is that this toolbox is community-ready and flexible.\nThe initial focus will be on delivering a limited number of novel diagnostics for NEMO configurations, but that the toolbox would be expanded to include other diagnostics and other ocean models.\n","excerpt":"COAsT (Coastal Ocean Assessment Toolkit) is a diagnostics and assessment python toolbox for …","ref":"/COAsT/docs/overview/","title":"Overview"},{"body":"Python as a language comes with more stringent recommendations than most when it comes to code styling. This is advantageous in our case as it gives us an obvious set of guidelines to adopt.\nWhen it comes to simple code styling, much of what\u0026rsquo;s recommended here will be copied from Python Enhancement Proposal (PEP) 8, an officially proposed and accepted Python style guide.\nCode Styling Conventions Let\u0026rsquo;s keep things simple to start with\u0026hellip;\n  Indentation should be achieved with spaces rather than tabs and each new level of indentation should be indented by four columns (i.e four spaces).\n  Any single line, including its indentation characters, should not exceed 79 characters in length.\n  Top-level (i.e at the module/file level rather than inside a function or class) function and class definitions should be separated by two blank lines.\n  Method (functions within a class) definitions are separated by a single blank line.\n  Usually, \u0026ldquo;import\u0026rdquo; statements should be on separate lines, that is to say that you should have one line per distinct module or package import. An exception to this rule is when multiple objects are imported from a single module or package, using a \u0026ldquo;from\u0026rdquo; statement, in which case individual objects can be imported on the same line, separated by commas.\n  PEP 8 does not make a recommendation relating to the use of double or single quotes in general use, but for the sake of consistency, this document suggests the use of double quotes wherever practical. This recommendation is intended for the sake of consistency with triple-quoted strings, as per Docstring Conventions (PEP 257).\n  Operators should be separated by single columns (i.e one space) either side, unless inside parentheses, in which case no whitespace is required.\n  Comments (beginning with the # character) should be indented as if they were code. In the case of inline comments, separate the comment with two spaces following the code it shares the line with.\n  All functions should contain a docstring, which provides basic information on its usage. For this project, the reStructuredText docstring format is suggested.\n  When it comes to naming variables and functions, snake case (lower_case_words_separated_by_underscores) is preferred. There are however a few exceptions to this rule: Class names should be styled as camel case (EveryNewWordIsCapitalised). Constants (Variables that should not be changed) can be indicated by the use of screaming snake case (UPPER_CASE_WORDS_SEPARATED_BY_UNDERSCORES). Note that this library currently targets Python 3.7, so the use of typing.Final official support for constant variables, new as of Python 3.8: is not currently supported.\n  In general, it is suggested to avoid the use of single-character variable names, but this is acceptable in certain cases, such as when defining coordinates (such as x, y and z), as these will be commonly recognized and enforcing different rules could cause confusion. PEP 8 advises the following regarding names to avoid: \u0026ldquo;Never use the characters \u0026lsquo;l\u0026rsquo; (lowercase letter el), \u0026lsquo;O\u0026rsquo; (uppercase letter oh), or \u0026lsquo;I\u0026rsquo; (uppercase letter eye) as single character variable names.\u0026rdquo; These specific characters should be avoided because they present an accessibility issue, as under many fonts these characters may be difficult to distinguish or completely indistinguishable from numerals one (1) and zero (0).\n  In the interest of readability, where named iterator variables are required, this document suggests the use of double characters (e.g. \u0026ldquo;ii\u0026rdquo; rather than \u0026ldquo;i\u0026rdquo;).\n  Object-Oriented Programming The general principles of OOP are fairly straightforward and well documented, so I won\u0026rsquo;t waste your precious time by regurgitating that particular wall of text here. Instead, I\u0026rsquo;ll focus on some general pointers specific to this language and use case.\n  In Python, all class attributes are technically public, but semantically, attributes can be designated as non-public by including leading underscores in the name. For instance, \u0026ldquo;my_variable\u0026rdquo; becomes \u0026ldquo;_my_variable\u0026rdquo;. These attributes are generally referred to as \u0026ldquo;protected\u0026rdquo;.\n  When you define a Python class, it is a best practice to inherit from the base object type. This convention stems from Python 2.X, as classes and types were not originally synonymous. This behaviour is implicit in Python 3.X but the convention has persisted nonetheless. Classes defined this way are referred to as \u0026ldquo;new-style\u0026rdquo; classes.\n  When defining a class that inherits from another, it is important to remember that overridden methods (in particular, this behaviour is important when dealing with __init__ methods) do not implicitly call the parent method. What this means is that unless you want to deliberately prevent the behaviour of the parent class (this is a very niche use-case), it is important to include a reference to the parent method. An example of this is: super().__init__() This functionality is advantageous as it prevents unnecessary duplication of code, which is a key tenet of object-oriented software.\n  ","excerpt":"Python as a language comes with more stringent recommendations than most when it comes to code …","ref":"/COAsT/docs/contributing_package/python_style/","title":"Python: Style"},{"body":"Coming soon\u0026hellip;\n","excerpt":"Coming soon\u0026hellip;","ref":"/COAsT/docs/examples/transect/","title":"Transect analysis"},{"body":"Prerequisites This package requires;\n python version 3.7+ Anaconda version 3.7  Are there any system requirements for using your project? What languages are supported (if any)? Do users need to already have any software or tools installed?\nInstallation This package should be installed by run;\nconda install -c conda-forge -c bodc coast However, there is also the option of;\npip install COAsT if you wish to install from source then got to GitHub and follow the README instructions\nSetup The base package should now be installed on your system. The following packages might be required for some of the advanced features;\n cartopy graphviz  Try it out! The below example works best with the COAsT example data. Start by importing COAsT:\nimport coast Now load a NEMO output file and domain file into a NEMO object (specifying the grid):\ndata_file = \u0026#39;\u0026lt;Path to NEMO data file\u0026gt;\u0026#39; domain_file = \u0026#39;\u0026lt;Path to NEMO domain file\u0026gt;\u0026#39; sci = coast.NEMO(data_file, domain_file, grid_ref = \u0026#39;t-grid\u0026#39;) You can now start having a look at some of the methods inside the NEMO class. Lets take a look at some altimetry data around the UK too:\naltimetry_file = \u0026#39;\u0026lt;Path to Altimetry data file\u0026gt;\u0026#39; altimetry = coast.ALTIMETRY(altimetry_file) ind = altimetry.subset_indices_lonlat_box([-10,10], [45,60]) altimetry = altimetry.isel(t_dim=ind) altimetry.quick_plot(\u0026#39;sla_filtered\u0026#39;) Now lets compare the model and altimetry Sea Surface Height using the Continuous Ranked Probability Score:\ncrps = coast.CRPS(sci, altimetry, \u0026#39;sossheig\u0026#39;,\u0026#39;sla_filtered\u0026#39;, nh_radius=30) And have a look at the resulting comparison:\ncrps.quick_plot() Nice one! Hopefully that all worked and you\u0026rsquo;re ready to take a look at the rest of the package and documentation.\n","excerpt":"Prerequisites This package requires;\n python version 3.7+ Anaconda version 3.7  Are there any system …","ref":"/COAsT/docs/getting-started/","title":"Getting Started"},{"body":"** Notes on Object Structure and Loading (for contributors):\nCOAsT is an object-orientated package, meaning that data is stored within Python object structures. In addition to data storage, these objects contain methods (subroutines) which allow for manipulation of this data. An example of such an object is the NEMO object, which allows for the storage and manipulation of NEMO output and domain data. It is important to understand how to load data using COAsT and the structure of the resulting objects.\nA NEMO object is created and initialised by passing it the paths of the domain and data files. Ideally, the grid type should also be specified (T, U, V or F in the case of NEMO). For example, to load in data from a file containing data on a NEMO T-grid:\nimport coast fn_data = '\u0026lt;path to T-grid data file(s)\u0026gt;' fn_domain = '\u0026lt;path to domain file\u0026gt;' data = coast.NEMO(fn_data, fn_domain, grid_ref='t-grid') Ideally, NEMO output data should be in grid-specific files, i.e. containing output variables situated on a NEMO T, U, V or F grid. The whole domain file is supplied, however only grid specific variables are placed into the NEMO object. A NEMO object therefore contains grid-specific data and all corresponding grid variables. One of the file names can beomitted (to get a data-only or grid only object), however functionality in this case will be limited.\nOnce loaded, data is stored inside the object using an xarray.dataset object. Following on from the previous code example, this can be viewed by calling:\ndata.dataset This reveals all netcdf-type aspects of the data and domain variables that were loaded, including dimensions, coordinates, variables and attributes. For example:\n\u0026lt;xarray.Dataset\u0026gt; Dimensions: (axis_nbounds: 2, t_dim: 7, x_dim: 297, y_dim: 375, z_dim: 51) Coordinates: time (t_dim) datetime64[ns] 2007-01-01T11:58:56 ... 2007-01-31T11:58:56 longitude (y_dim, x_dim) float32 ... latitude (y_dim, x_dim) float32 ... Dimensions without coordinates: axis_nbounds, t_dim, x_dim, y_dim, z_dim Data variables: deptht_bounds (z_dim, axis_nbounds) float32 ... sossheig (t_dim, y_dim, x_dim) float32 ... time_counter_bounds (t_dim, axis_nbounds) datetime64[ns] ... time_instant (t_dim) datetime64[ns] ... temperature (t_dim, z_dim, y_dim, x_dim) float32 ... e1 (y_dim, x_dim) float32 ... e2 (y_dim, x_dim) float32 ... e3_0 (z_dim, y_dim, x_dim) float32 1.0 1.0 1.0 ... 1.0 1.0 Variables may be obtained in a number of ways. For example, to get temperature data, the following are all equivalent:\ntemp = data.dataset.temperature temp = data.dataset['temperature'] temp = data['temperature'] These commands will all return an xarray.dataarray object. Manipulation of this object can be done using xarray commands, for example indexing using [] or xarray.isel. Be aware that indexing will preserve lazy loading, however and direct access or modifying of the data will not. For this reason, if you require a subset of the data, it is best to index first.\nThe names of common grid variables are standardised within the COAsT package for consistency and ease of use. Along with their original NEMO names, these are:\n longitude [glamt / glamu / glamv / glamf] latitude [gphit / gphiu / gphiv / gphif] time [time_counter] e1 [e1t / e1u / e1v / e1f] (dx variable) e2 [e1t / e1u / e1v / e1f] (dy variable) e3_0 [e3t_0 / e3u_0 / e3v_0 / e3f_0] (dz variable at time 0)  Longitude, latitude and time are also set as coordinates. You might notice that dimensions are also standardised:\n x_dim The dimension for the x-axis (longitude) y_dim The dimension for the y-axis (latitude) t_dim The dimension for the time axis z_dim The dimension for the depth axis.  Wherever possible, the aim is to ensure that all of the above is consistent across the whole COAsT toolbox. Therefore, you will also find the same names and dimensions in, for example observation objects. Future objects, where applicable, will also follow these conventions. If you (as a contributor) add new objects to the toolbox, following the above template is strongly encouraged. This includes using xarray dataset/dataarray objects where possible, adopting an object oriented approach and adhering to naming conventions.\n","excerpt":"** Notes on Object Structure and Loading (for contributors):\nCOAsT is an object-orientated package, …","ref":"/COAsT/docs/contributing_package/python_structure/","title":"Python: Structure"},{"body":"A demonstration of pycnocline depth and thickness diagnostics. The first and second depth moments of stratification are computed as proxies for pycnocline depth and thickness, suitable for a nearly two-layer fluid.\nimport coast import numpy as np import os import xarray as xr import dask import matplotlib.pyplot as plt import matplotlib.colors as colors # colormap fiddling Load in the data After downloading the example files and placing the example_files directory in your working directory, set some aliases and load the t-grid data:\n# set some paths config = \u0026#39;AMM7\u0026#39; dn_files = \u0026#34;./example_files/\u0026#34; dn_fig = \u0026#34;\u0026#34; # somewhere to put the figures fn_nemo_grid_t_dat = \u0026#39;nemo_data_T_grid_Aug2015.nc\u0026#39; fn_nemo_dom = \u0026#39;COAsT_example_NEMO_domain.nc\u0026#39; sci_t = coast.NEMO(dn_files + fn_nemo_grid_t_dat, dn_files + fn_nemo_dom, grid_ref=\u0026#39;t-grid\u0026#39;, multiple=True) The stratification variables are computed as centred differences of the t-grid variables. These will become w-grid variables. So, create an empty w-grid object, to store stratification.\nsci_w = coast.NEMO( fn_domain = dn_files + fn_nemo_dom, grid_ref=\u0026#39;w-grid\u0026#39;) Subset the domain We are not interested in the whole doman so it is computationally efficient to subset the data for the region of interest. Here we will look at the North Sea between (51N: 62N) and (-4E:15E). We will great subset objects for both the t- and w-grids:\nind_sci = sci_t.subset_indices([51,-4], [62,15]) sci_nwes_t = sci_t.isel(y_dim=ind_sci[0], x_dim=ind_sci[1]) #nwes = northwest european shelf ind_sci = sci_w.subset_indices([51,-4], [62,15]) sci_nwes_w = sci_w.isel(y_dim=ind_sci[0], x_dim=ind_sci[1]) #nwes = northwest european shelf Diagnostic calculations and plotting We can use a COAsT method to construct the in-situ density:\nsci_nwes_t.construct_density( EOS=\u0026#39;EOS10\u0026#39; ) Then we construct stratification using a COAsT method to take the vertical derivative. Noting that the inputs are on t-pts and the outputs are on w-pts\nsci_nwes_w = sci_nwes_t.differentiate( \u0026#39;density\u0026#39;, dim=\u0026#39;z_dim\u0026#39;, out_varstr=\u0026#39;rho_dz\u0026#39;, out_obj=sci_nwes_w ) # --\u0026gt; sci_nwes_w.rho_dz This has created a variable called sci_nwes_w.rho_dz.\nWe can now use the INTERNALTIDE class to construct the first and second moments (over depth) of density. In the limit of an idealised two-layer fluid these converge to the depth and thickness of the interface. I.e. the pycnocline depth and thickness respectively.\n#%% Create internal tide diagnostics object IT = coast.INTERNALTIDE(sci_nwes_t, sci_nwes_w) #%% Construct pycnocline variables: depth and thickness IT.construct_pycnocline_vars( sci_nwes_t, sci_nwes_w ) Finally we plot pycnocline variables (depth and thickness) using an INTERNALTIDES method:\nIT.quick_plot() for example the pycnocline depth map. In the interest of simplicity, unstratified areas are masked (this includes the land):  \n","excerpt":"A demonstration of pycnocline depth and thickness diagnostics. The first and second depth moments of …","ref":"/COAsT/docs/examples/stratification/","title":"Stratification diagnostics"},{"body":"Load and inspect Data Much of the capability leverages the excellent xarray package. Following an import of the package. Load some data and inspect:\nimport coast dir = \u0026#39;\u0026lt;path-to-files\u0026gt;\u0026#39; sci = coast.NEMO() sci.load(dir + \u0026#39;AMM7_1d_20070101_20070131_25hourm_grid_T.nc\u0026#39;,{\u0026#39;time_counter\u0026#39;:10}) sci.dataset Multiple loads Alternatively multiple files can be loaded simultaneously using wildcards:\nsci.load_multiple(dir + \u0026#39;AMM7_1d*nc\u0026#39;, {\u0026#39;time_counter\u0026#39;: 25}) Subsetting methods for data To subsetting data there are methods to find the appropriate indices from the domain configuration data.\nTransects Transects through data can be found using a method in the DOMAIN class to extract the indices along a transect defined by end points in a grid.\nFirst load the domain configuration data:\n# load domain data dir = \u0026#39;\u0026lt;path-to-files\u0026gt;\u0026#39; sci_dom = coast.DOMAIN() sci_dom.load(dir+\u0026#39;domain_cfg.nc\u0026#39;) Then use the transect_indices method between defined lat-lon end points:\nyt, xt, length_of_line = sci_dom.transect_indices([42,-3],[43,-2], grid_ref=\u0026#39;t\u0026#39;) (For grid_ref any of the following is allowed: t,u,v,f. If missing t is assumed.)\nOptionally visualize:\n# Visualise import numpy as np import matplotlib.pyplot as plt lon = np.array( sci_dom.dataset.nav_lon ) lat = np.array( sci_dom.dataset.nav_lat ) plt.plot( lon[yt,xt], lat[yt,xt], \u0026#39;.\u0026#39;); plt.show() Within a distance from a point Alternatively indices can be sought in proximity to a defined point in lat-lon space:\n# load domain data dir = \u0026#39;\u0026lt;path-to-files\u0026gt;\u0026#39; sci_dom = coast.DOMAIN() sci_dom.load(dir+\u0026#39;domain_cfg.nc\u0026#39;) # Find indices for points with 111 km from 0E, 51N ind = sci_dom.subset_indices_by_distance(0,51,111) lon = np.array( sci_dom.dataset.nav_lon ) lat = np.array( sci_dom.dataset.nav_lat ) # Visualise import matplotlib.pyplot as plt plt.plot( lon[ind[0], ind[1]], lat[ind[0], ind[1]], \u0026#39;+\u0026#39; ) plt.show() Extract the variable on the subset subset_indices Then you have to extract the desired variable on the subset of indices. For example, loading a single file and extracting temperature\nimport coast dir = \u0026#39;\u0026lt;path-to-files\u0026gt;\u0026#39; sci_dom = coast.DOMAIN() sci = coast.NEMO() sci_dom.load(dir+\u0026#34;domain_cfg.nc\u0026#34;) sci.load(dir+\u0026#39;AMM7_1d_20070101_20070131_25hourm_grid_T.nc\u0026#39;, {\u0026#39;time_counter\u0026#39;: 25}) yi,xi,line_len = sci_dom.transect_indices([51,-5],[49,-9], grid_ref=\u0026#39;t\u0026#39;) # Extact the variable data_t = sci.get_subset_as_xarray(\u0026#34;votemper\u0026#34;,xi,yi) or loading multiple files and extracting temperature\nimport coast dir = \u0026#39;\u0026lt;path-to-files\u0026gt;\u0026#39; sci_dom = coast.DOMAIN() sci_multiple = coast.NEMO() sci_dom.load(dir+\u0026#34;domain_cfg.nc\u0026#34;) sci_multiple.load_multiple(dir+\u0026#34;A*.nc\u0026#34;, {\u0026#39;time_counter\u0026#39;: 25}) yi,xi,line_len = sci_dom.transect_indices([51,-5],[49,-9], grid_ref=\u0026#39;t\u0026#39;) # Extact the variable data_multiple_t = sci_multiple.get_subset_as_xarray(\u0026#34;votemper\u0026#34;,xi,yi) Or extracting velocity (on a different grid)\nimport coast dir = \u0026#39;\u0026lt;path-to-files\u0026gt;\u0026#39; sci_dom = coast.DOMAIN() sci = coast.NEMO() sci_dom.load(dir+\u0026#34;domain_cfg.nc\u0026#34;) sci.load(dir+\u0026#39;AMM7_1d_20070101_20070131_25hourm_grid_U.nc\u0026#39;, {\u0026#39;time_counter\u0026#39;: 25}) # load in a velocity dataset yi,xi,line_len = sci_dom.transect_indices([51,-5],[49,-9], grid_ref=\u0026#39;u\u0026#39;) # Extract transect indices on u-pts # Extract the variable data_u = sci.get_subset_as_xarray(\u0026#34;vozocrtx\u0026#34;,xi,yi) Other stuff Just a mo. Will probably put the extract a transect and plot example here.\nContinuous Ranked Probability Score (CRPS) This is a basic script for running the CRPS function with the example NEMO data and Altimetry data. Altimetry data currently being read in using netCDF4 and cut out of global domain before being given to the routine.\nimport coast import numpy as np fn_dom = \u0026#39;\u0026lt;dir\u0026gt;/COAsT_example_NEMO_domain.nc\u0026#39; fn_dat = \u0026#39;\u0026lt;dir\u0026gt;/COAsT_example_NEMO_data.nc\u0026#39; fn_alt = \u0026#39;\u0026lt;dir\u0026gt;/COAsT_example_altimetry_data.nc\u0026#39; nemo_dom = coast.DOMAIN() nemo_var = coast.NEMO() alt_test = coast.ALTIMETRY() nemo_dom.load(fn_dom) nemo_var.load(fn_dat) alt_test.load(fn_alt) alt_test.set_command_variables() nemo_var.set_command_variables() nemo_dom.set_command_variables() # Extract lon/lat box (saves into alt_test object) alt_test.extract_lonlat_box([-10,10], [45,65]) # Just use the first 3 elements of remaining altimetry data alt_test.extract_indices_all_var(np.arange(0,4)) crps_test = nemo_var.crps_sonf(\u0026#39;ssh\u0026#39;, nemo_dom, alt_test, \u0026#39;sla_filtered\u0026#39;, nh_radius=111, nh_type = \u0026#34;radius\u0026#34;, cdf_type = \u0026#34;empirical\u0026#34;, time_interp = \u0026#34;nearest\u0026#34;, plot=True) This is the final element on the page and there should be no margin below this. ","excerpt":"Load and inspect Data Much of the capability leverages the excellent xarray package. Following an …","ref":"/COAsT/docs/examples/code-snippet/","title":"Code snippets"},{"body":"What is Dask Dask is a python library that allows code to be run in parallel based on the hardware your running on. This means Dask works just as well on your laptop as on your large server.\nUsing Dask Dask is included in the xarray library, when loading a data source (file/NumPy array) you can turn Dask on by setting the chunks variable\nnemo_t = coast.NEMO( fn_data=dn_files+fn_nemo_grid_t_dat, fn_domain=dn_files+fn_nemo_dom, grid_ref=\u0026#39;t-grid\u0026#39;, chunks={\u0026#34;time_counter\u0026#34;:3}) chunks tell Dask where to break your data across the different processor tasks.\nDirect Dask Dask can be imported and used directly\nimport Dask.array as da big_array = da.multiple(array1,array2) Dask arrays follow the NumPy API. This means that most NumPy functions have a Dask version.\nPotential Issues Dask objects are immutable. This means that the classic approach, pre-allocation follow by modification will not work.\nThe following code will error.\nimport Dask.array as da e3w_0 = da.squeeze(dataset_domain.e3w_0) depth_0 = da.zero_like(e3w_0) depth_0[0, :, :] = 0.5 * e3w_0[0, :, :] # this line will error out option 1 Continue using NumPy function but wrapping the final value in a Dask array. This final Dask object will still be in-memory.\ne3w_0 = np.squeeze(dataset_domain.e3w_0) depth_0 = np.zeros_like(e3w_0) depth_0[0, :, :] = 0.5 * e3w_0[0, :, :] depth_0[1:, :, :] = depth_0[0, :, :] + np.cumsum(e3w_0[1:, :, :], axis=0) depth_0 = da.array(depth_0) option 2 Dask offers a feature called delayed. This can be used as a modifier on your complex methods as follows;\n@Dask.delayed def set_timezero_depths(self, dataset_domain): # complex workings these do not return the computed answer, rather it returns a delayed object. These delayed object get stacked, as more delayed methods are called. When the value is needed, it can be computed like so;\nne = coast.NEMO(...) # come complex delayed methods called ne.data_variable.compute() Dask will now work out a computing path via all the required methods using as many processor tasks as possible.\nVisualising the Graph Dask is fundamentally a computational graph library, to understand what is happening in the background it can help to see these graphs (on smaller/simpler problems). This can be achieved by running;\nne = coast.NEMO(...) # come complex delayed methods called ne.data_variable.visualize() this will output a png image of the graph in the calling directory and could look like this;\n  ","excerpt":"What is Dask Dask is a python library that allows code to be run in parallel based on the hardware …","ref":"/COAsT/docs/contributing_package/dask/","title":"Dask"},{"body":"The Github page for this package can be found here\nThe rest of this page is coming soon.\n","excerpt":"The Github page for this package can be found here\nThe rest of this page is coming soon.","ref":"/COAsT/docs/contributing-docs/github_workflow/","title":"Github Workflow"},{"body":"Example data are provided for the following tutorial. Download these files and place the example_files directory in your working directory.\nThe following tutorial is split into sections:\n","excerpt":"Example data are provided for the following tutorial. Download these files and place the …","ref":"/COAsT/docs/examples/","title":"Examples"},{"body":"Here you will find information needed to contribute code changes to the COAsT package.\n","excerpt":"Here you will find information needed to contribute code changes to the COAsT package.","ref":"/COAsT/docs/contributing_package/","title":"Contributing: COAsT"},{"body":"We use Hugo Extended Version to format and generate our website, the Docsy theme for styling and site structure, and GitHub pages to manage the deployment of the site. Hugo is an open-source static site generator that provides us with templates, content organisation in a standard directory structure, and a website generation engine. You write the pages in Markdown (or HTML if you want), and Hugo wraps them up into a website.\nAll submissions, including submissions by project members, require review. We use GitHub pull requests for this purpose. Consult GitHub Help for more information on using pull requests.\nUpdating a single page If you\u0026rsquo;ve just spotted something you\u0026rsquo;d like to change while using the docs, Docsy has a shortcut for you:\n Click Edit this page in the top right hand corner of the page. If you don\u0026rsquo;t already have an up to date fork of the project repo, you are prompted to get one - click Fork this repository and propose changes or Update your Fork to get an up to date version of the project to edit. The appropriate page in your fork is displayed in edit mode. make your edit submit a pull request with a summary of the changes  Previewing your changes locally If you want to run your own local Hugo server to preview your changes as you work:\n  Follow the instructions in Getting started to install Hugo and any other tools you need. You\u0026rsquo;ll need at least Hugo version 0.45 (we recommend using the most recent available version), and it must be the extended version, which supports SCSS.\n  Fork the COAsT-site repo repo into your own project, then create a local copy using git clone. Don’t forget to use --recurse-submodules or you won’t pull down some of the code you need to generate a working site.\ngit clone --recurse-submodules --depth 1 https://github.com/British-Oceanographic-Data-Centre/COAsT-site.git   Run npm install to install Node.js dependencies.\n  Run hugo server in the site root directory. By default your site will be available at http://localhost:1313/COAsT. Now that you\u0026rsquo;re serving your site locally, Hugo will watch for changes to the content and automatically refresh your site.\n  Continue with the usual GitHub workflow to edit files, commit them, push the changes up to your fork, and create a pull request.\n  Creating an issue If you\u0026rsquo;ve found a problem in the docs, but you\u0026rsquo;re not sure how to fix it yourself, please create an issue in the COAsT-site repo. You can also create an issue about a specific page by clicking the Create Issue button in the top right hand corner of the page.\nUseful resources  Docsy user guide: All about Docsy, including how it manages navigation, look and feel, and multi-language support. Hugo documentation: Comprehensive reference for Hugo. Github Hello World!: A basic introduction to GitHub concepts and workflow.  ","excerpt":"We use Hugo Extended Version to format and generate our website, the Docsy theme for styling and …","ref":"/COAsT/docs/contributing-docs/","title":"Contributing: Documentation"},{"body":"This page will walk you though a simple setup for hugo extended - which is needed if want to view any changes you make to this site locally.\nFor more details please read this.\nInstallation Manual  Download hugo extended from GitHub Unzip into preferred location (I use C:\\hugo) Add to OS PATH  optional but makes usage easier    Via a Package Manager On Windows you can use Chocolately to install with:\nchoco install hugo-extended Or on macOS/Linux you can use Homebrew to install with:\nbrew install hugo Try it out! You should now be able to try the following in a terminal\n$ hugo --help if you have cloned the COAsT-site repo you should also now be able to;\n$ cd COAsT-site $ hugo server the above will start a local hugo powered version of the website. you can edit any of the files under /content and see your changes at http://localhost:1313/COAsT/\n","excerpt":"This page will walk you though a simple setup for hugo extended - which is needed if want to view …","ref":"/COAsT/docs/contributing-docs/hugo/","title":"setting up Hugo"},{"body":"","excerpt":"","ref":"/COAsT/docs/reference/","title":"Reference"},{"body":"Code functionality tests are written in unit_testing/unit_testing.py in the COAsT repository, and therefore contain working examples of the package. These are written to verify the package functionality and to maintain operability following code updates.\nAt the time of writing these included:\n1. Loading \u0026amp; Initialisation a. Loading NEMO data file b. Loading Altimetry file c. Load data from existing dataset d. Set NEMO variable name e. Set NEMO grid attribute - dimension names f. Load only Domain g. Calculate depth_0 for t,u,v,w,f grids h. Load NEMO that is a subregion in the domain file i. Multi load (over time) for NEMO files  2. General Utility Methods in COAsT a. Copying a COAsT object b. COAsT ``__getitem__`` returns variable c. Renaming variables inside a COAsT object  3. Diagnostic Methods a. Compute vertical spatial derivative b. Construct density method inside NEMO class c. Construct pycnocline depth and thickness d. Plot pycnocline depth  4. Transect Methods a. Determine and extract transect indices b. Transport velocity and depth calculations c. Transport and velocity plotting d. Contrust density on z-levels along the transect. Compare with item 3b. e. Geostrophic velocity \u0026amp; transport calculations  5. Object Manipulation (e.g. indexing, subsetting) a. Subsetting single variable b. Indices by distance c. Subsetting entire COAsT object and return as copy d. Find nearest xy indices e. ``NEMO.interpolate_in_space()`` f. ``NEMO.interpolate_in_time()``  6. Validation Methods a. Calculate single obs CRPS values using different methods b. CRPS map plot c. CRPS CDF plot d. Interpolate model to altimetry  7. Plotting Methods a. Altimetry ``quick_plot()`` b. Open, view and save tide gauge data from GESLA database  ","excerpt":"Code functionality tests are written in unit_testing/unit_testing.py in the COAsT repository, and …","ref":"/COAsT/docs/examples/unit_testing/","title":"Unit testing"},{"body":"AMM15 - 1.5km resolution Atlantic Margin Model \u0026#34;\u0026#34;\u0026#34; AMM15_example_plot.py Make simple AMM15 SST plot. \u0026#34;\u0026#34;\u0026#34; #%% import coast import numpy as np import xarray as xr import matplotlib.pyplot as plt import matplotlib.colors as colors # colormap fiddling ################################################# #%% Loading data ################################################# config = \u0026#39;AMM15\u0026#39; dir_nam = \u0026#34;/projectsa/NEMO/gmaya/2013p2/\u0026#34; fil_nam = \u0026#34;20130415_25hourm_grid_T.nc\u0026#34; dom_nam = \u0026#34;/projectsa/NEMO/gmaya/AMM15_GRID/amm15.mesh_mask.cs3x.nc\u0026#34; sci_t = coast.NEMO(dir_nam + fil_nam, dom_nam, grid_ref=\u0026#39;t-grid\u0026#39;, multiple=False) # create an empty w-grid object, to store stratification sci_w = coast.NEMO( fn_domain = dom_nam, grid_ref=\u0026#39;w-grid\u0026#39;) print(\u0026#39;* Loaded \u0026#39;,config, \u0026#39; data\u0026#39;) ################################################# #%% subset of data and domain ## ################################################# # Pick out a North Sea subdomain print(\u0026#39;* Extract North Sea subdomain\u0026#39;) ind_sci = sci_t.subset_indices([51,-4], [62,15]) sci_nwes_t = sci_t.isel(y_dim=ind_sci[0], x_dim=ind_sci[1]) #nwes = northwest europe shelf ind_sci = sci_w.subset_indices([51,-4], [62,15]) sci_nwes_w = sci_w.isel(y_dim=ind_sci[0], x_dim=ind_sci[1]) #nwes = northwest europe shelf #%% Apply masks to temperature and salinity if config == \u0026#39;AMM15\u0026#39;: sci_nwes_t.dataset[\u0026#39;temperature_m\u0026#39;] = sci_nwes_t.dataset.temperature.where( sci_nwes_t.dataset.mask.expand_dims(dim=sci_nwes_t.dataset[\u0026#39;t_dim\u0026#39;].sizes) \u0026gt; 0) sci_nwes_t.dataset[\u0026#39;salinity_m\u0026#39;] = sci_nwes_t.dataset.salinity.where( sci_nwes_t.dataset.mask.expand_dims(dim=sci_nwes_t.dataset[\u0026#39;t_dim\u0026#39;].sizes) \u0026gt; 0) else: # Apply fake masks to temperature and salinity sci_nwes_t.dataset[\u0026#39;temperature_m\u0026#39;] = sci_nwes_t.dataset.temperature sci_nwes_t.dataset[\u0026#39;salinity_m\u0026#39;] = sci_nwes_t.dataset.salinity #%% Plots fig = plt.figure() plt.pcolormesh( sci_t.dataset.longitude, sci_t.dataset.latitude, sci_t.dataset.temperature.isel(z_dim=0).squeeze()) #plt.xlabel(\u0026#39;longitude\u0026#39;) #plt.ylabel(\u0026#39;latitude\u0026#39;) #plt.colorbar() plt.axis(\u0026#39;off\u0026#39;) plt.show() fig.savefig(\u0026#39;AMM15_SST_nocolorbar.png\u0026#39;, dpi=120)    India subcontinent maritime domain. WCSSP India configuration #%% import coast import numpy as np import xarray as xr import dask import matplotlib.pyplot as plt import matplotlib.colors as colors # colormap fiddling ################################################# #%% Loading data ################################################# dir_nam = \u0026#34;/projectsa/COAsT/NEMO_example_data/MO_INDIA/\u0026#34; fil_nam = \u0026#34;ind_1d_cat_20180101_20180105_25hourm_grid_T.nc\u0026#34; dom_nam = \u0026#34;domain_cfg_wcssp.nc\u0026#34; sci_t = coast.NEMO(dir_nam + fil_nam, \\ dir_nam + dom_nam, grid_ref=\u0026#39;t-grid\u0026#39;, multiple=False) #%% Plot fig = plt.figure() plt.pcolormesh( sci_t.dataset.longitude, sci_t.dataset.latitude, sci_t.dataset.temperature.isel(t_dim=0).isel(z_dim=0)) plt.xlabel(\u0026#39;longitude\u0026#39;) plt.ylabel(\u0026#39;latitude\u0026#39;) plt.title(\u0026#39;WCSSP India SST\u0026#39;) plt.colorbar() plt.show() fig.savefig(\u0026#39;WCSSP_India_SST.png\u0026#39;, dpi=120)    South East Asia, 1/12 deg configuration (ACCORD: SEAsia_R12) #%% import coast import numpy as np import xarray as xr import dask import matplotlib.pyplot as plt import matplotlib.colors as colors # colormap fiddling ################################################# #%% Loading data ################################################# dir_nam = \u0026#34;/projectsa/COAsT/NEMO_example_data/SEAsia_R12/\u0026#34; fil_nam = \u0026#34;SEAsia_R12_5d_20120101_20121231_gridT.nc\u0026#34; dom_nam = \u0026#34;domain_cfg_ORCA12_adj.nc\u0026#34; sci_t = coast.NEMO(dir_nam + fil_nam, \\ dir_nam + dom_nam, grid_ref=\u0026#39;t-grid\u0026#39;, multiple=False) #%% Plot fig = plt.figure() plt.pcolormesh( sci_t.dataset.longitude, sci_t.dataset.latitude, sci_t.dataset.soce.isel(t_dim=0).isel(z_dim=0)) plt.xlabel(\u0026#39;longitude\u0026#39;) plt.ylabel(\u0026#39;latitude\u0026#39;) plt.title(\u0026#39;SE Asia, surface salinity (psu)\u0026#39;) plt.colorbar() plt.show() fig.savefig(\u0026#39;SEAsia_R12_SSS.png\u0026#39;, dpi=120)    ","excerpt":"AMM15 - 1.5km resolution Atlantic Margin Model \u0026#34;\u0026#34;\u0026#34; AMM15_example_plot.py Make simple …","ref":"/COAsT/docs/examples/configs_gallery/","title":"Configuration Gallery"},{"body":"__________________________________________________________________________________________ ______ ___ _ _________ .' ___ | .' `. / \\ | _ _ | / .' \\_|/ .-. \\ / _ \\ .--.|_/ | | \\_| | | | | | | / ___ \\ ( (`\\] | | \\ `.___.'\\\\ `-' /_/ / \\ \\_ `'.'. _| |_ `.____ .' `.___.'|____| |____|[\\__) )|_____| Coastal Ocean Assessment Toolbox https://www.nemo-ocean.eu/ Version 0.2.1a10 (alpha build) __________________________________________________________________________________________ COAsT is a Python package for managing and analysing high resolution NEMO output. Here you can find information on obtaining, installing and using COAsT as well as guidelines for contributing to the project.\nThis documentation site is still under construction but you can still find guidelines for contributing to the package and this website. See below for description of each section.\n","excerpt":"__________________________________________________________________________________________ ______ …","ref":"/COAsT/docs/","title":"Documentation"},{"body":"","excerpt":"","ref":"/COAsT/docs/reference/parameter-reference/","title":"Parameter Reference"},{"body":"  #td-cover-block-0 { background-image: url(/COAsT/about/featured-background_hu14d69772da4446f8c45afbc4cad362c8_132726_960x540_fill_q75_catmullrom_top.jpg); } @media only screen and (min-width: 1200px) { #td-cover-block-0 { background-image: url(/COAsT/about/featured-background_hu14d69772da4446f8c45afbc4cad362c8_132726_1920x1080_fill_q75_catmullrom_top.jpg); } }  About COAsT A site using the Docsy Hugo theme. --        COAsT is a Python package for managing and analysing high resolution NEMO output Read more here     This site was based off the Docsy Hugo theme.    ","excerpt":"  #td-cover-block-0 { background-image: …","ref":"/COAsT/about/","title":"About Goldydocs"},{"body":"  #td-cover-block-0 { background-image: url(/COAsT/featured-background_hu14d69772da4446f8c45afbc4cad362c8_132726_960x540_fill_q75_catmullrom_top.jpg); } @media only screen and (min-width: 1200px) { #td-cover-block-0 { background-image: url(/COAsT/featured-background_hu14d69772da4446f8c45afbc4cad362c8_132726_1920x1080_fill_q75_catmullrom_top.jpg); } }  Welcome to the documentation: A Docsy site for COAsT Learn More   Download   COAsT\n\n        This is a single web UI providing visibility into the COAsT python framework.       Download from Anaconda.org Get the COAsT framework!\nRead more …\n   Contributions welcome! We do a Pull Request contributions workflow on GitHub. New users are always welcome!\nRead more …\n   Follow us on Twitter! For announcement of latest features etc.\nRead more …\n    ","excerpt":"#td-cover-block-0 { background-image: …","ref":"/COAsT/","title":"COAsT"},{"body":"","excerpt":"","ref":"/COAsT/community/","title":"Community"},{"body":"","excerpt":"","ref":"/COAsT/search/","title":"Search Results"}]